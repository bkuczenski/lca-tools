==========
Sun Mar 12 22:38:10 -0700 2017

What do we want an LcMatrix to do?

More to the point, what do we want an LcCatalog to do?
1- this is the thing that keeps track of compartments
2- this is the thing that keeps track of [archive] refs
 2a- CatalogRef should be catalog (or None for floating ref), ref (i.e. LcArchive.ref), id (or key)
 2b- CatalogRef can be created w/o a catalog (floating) and be anchored to a catalog later

3- json archives are not the point / data should be omitted (a la in Semantic Catalogs)

4- time for fuckin bed.

==========
Sun Mar 05 00:19:37 -0800 2017

Progress on catalog / fg manager refactor:

 - make upstream the *default*- only replicate entities into downstream archives when asked
 - catalog is stupid. why base the whole thing on a fragile sequential index?

 - catalog refs should be [catalog, ref, id] where ref is LcArchive.ref, and the catalog manager looks it up into a list.
 - that way, each serialized entity is completely specified on its own.

 - catalog manager should dereference and should load on demand

 - and some sort of librarian should have a master list of all the entities.
 - gzip catalogs should omit data (just like I said)

 - don't feel like switching into code mode right now
 - load should recurse on upstreams.

But the point is, the catalog ref can be assigned a catalog manager.  CatalogRef.lookup(catalog) should dereference it and be immutable.
And then the catalog manager stores its list of known catalogs by .ref

Foreground: is upstream of all archives that don't have an upstream.  archives that do have an upstream, load them recursively, until you land back at foreground.  that's your ordering.

then from each archive, you can look up -> fg flows as interior, non-cutoff; fg emissions as cutoffs.


 - background:
   : already spits out a list of fg fragments and outputs
   -> need to move it into main
   -> get rid of extraneous stuff in LcArchive as well, with terminations and such-
   -> background should report: it all. entity map: Af entities (foreground sccs), Ad entities (background + downstream, interior), Bf entities (cutoff)
      -> background should aggregate- via inversion for Af and iteration for A*? that's the shit I havent done yet
      - should create fragments and give them UUIDs (uuid3 via termination? no. simply enumerate them.)
      - the fragment's origin then becomes whatever foreground queries it. 

   - manager should: ask for a list of fragments
     : given one fragment - get children-> column of af
       	     	 	  - fg inventory -> columns of ad and bf
			  - bg lci -> column of bx
     : foreground should then ask flow db for cfs for the named flow, given the qtys loaded.







==========
Tue Feb 21 13:35:50 -0800 2017

OK- progress- we now have built A and B matrices, and we have an Ecoinvent Tarjan traversal in <25 sec, which is shorter than it takes to load the JSON file. (AND we implemented allocated exchange deserialization)

Moving forward, on the refactoring side: we need to
 * figure out what the foreground should do, and how matrix bg computation should fit into it
 * figure out an interface for the foreground manager-- I suppose this should do that
 * split entities / move deserialize into entities + exchanges
 * flowdb -> quantity db; move to catalog from mgr

 - review catalog, develop interface
 - review interfaces


What is currently required to perform foreground queries?

 - retrieve quantities from index 0 by uuid
 - fragment_lcia(frag, **kwargs)
 - fg_lcia(catalog_ref)
 - frag(abbreviation)
 - ref(index, id)

fg_lcia simply dereferences the process and runs the process's lcia
fragment_lcia simply requires each fragment's score cache to be set-- it's practically static

so what about compute_unit_scores? static, static, static.

what does the manager even do? it's just a collection of utility functions.


The whole thing needs reworked.  None of the current manager tasks need to be done by a manager- they should be done by the entities themselves.  A process can compute its own fg_lcia (and with matrix, its own bg_lcia)

except not, because the foreground flows are supposed to be the ones that are characterized.  The foreground should be doing the lcia-- the archives should just be doing LCI? but that still doesn't help because the LCI they return will include heterodox flows.

They should return Emission objects- just a flow uuid and direction (and value) and then the foreground can do the LCIA using its "correct" flows of record (which are rendered correct through the use of a quantity db)

The Foreground should NOT store fragments, though-- the manager should store fragments.  ALL the manager should do is store and manage fragments and their unit score computations.

A SEPARATE builder class (not a subclass) should be used for consstructing fragments which can then be added to a fragment manager.

The manager should still be made up of a catalog.

All the "child flows" and "fragment to foreground" stuff was written blind- it should all be thrown out. I should start new.





Vision for how things should work:

 * Entities: get separate files.

 * LcArchive:
   * can be marked background- if true, then entities may not be added; and edits (esp. to process reference exchanges) may produce unreliable results.
   * once an archive is marked background, the archive can identify:
     -- foreground flows (product flows in non-background sccs)
     -- background flows (core and downstream)
     -- cutoff flows
     * for a given process+ref flow, return interior exchanges (exchanges found in _terminations)
     * for a given process+ref flow, return direct cutoffs (exchanges not found in _terminations)
     * for a given process+ref flow, return LCI (agg cutoffs)
     == all of these are delivered as (flow.uuid, direction, value)
     [=> dissipation flows only work in the foreground]
     * background can also return disagg or agg foreground, dependencies, emissions
     * foreground does LCIA computation on the results
     * archives can also be mined to construct fragment trees, instead of the absurd build_child_flows and the like
     
   ** problems: mainly we want the compartment manager to detect intermediate vs elementary flows, but that is something that we really want the entities to do for themselves.
   ** it's not really intermediate vs elementary that we're interested in, though- it's interior vs exterior-
      - for gen_exchanges we want interior flows to build child fragments
      - for lcia we want exterior flows to estimate impacts
      - what knows interior vs exterior? **the background!** how does it know?
      	- _terminations tell us whether flows are interior or exterior- the problem is initializing it-
	  = what happens if a process's reference changes- how does _terminations get updated?
	  = either we disallow that, or we have to provide hooks. hooks don't seem feasible.
	  = what we CAN do is disallow new entity addition after bg is computed- but that still doesn't prevent changes to existing processes. I think it's just a "void your warranty" situation: once the bg is computed, you can't mess with it anymore.
	  So anyway, the key into _terminations is the same as the key into _emissions: (flow uuid, direction) from a parent exchange.  Except _terminations is complete; _emissions only includes emissions that are part of the background.  So membership in _terminations should be the determining factor for interiority.

	  This is great- this completely eliminates the need for a compartment manager. And since we create _terminations on __init__, we don't even need to build the background!
	- emissions are a list of flows + directions- those we can find right away using the bg.



 * Quantity DB: as before, maps flowable + compartment to CF.
   -> contains its own compartment manager, serializes to compartments.json
   -> compartment manager should also compartmentalize & dereference quantities -> semantic


We still would need to load the whole archive before we can initialize background.


 * Catalog--> contains a foreground and a quantity db.
   -> serializes to catalog.json-- should include fg-specific flow synonyms as well

 * Catalog[0] is foreground:
   -> privileged archive because it stores authoritative flow profile data
   -> serializes to entities.json in catalog directory

 * FragmentManager is built on top of a catalog
   -> keeps a list of fragments; serializes + deserializes them in the fragments/ directory in foreground
   -> all the tricky fragment creation stuff comes out--> done using matrices instead.
   -> backgrounds create fragments now, and hand them over to the manager to store.
   


In order to "do everything", which in this case is compute a fragment LCIA,
 * I believe, to traverse, all we need is the fragment trees- we don't even use the term nodes
 * to compute unit scores:
   - if the fragment is background, do background LCIA
   - elif the fragment is foreground, lookup CFs from fragment.flow (currently using db.factors_for_flow
   - else, do foreground LCIA

Then traversal_to_lcia does not seem to make any further requirements. so- seriously- the fragments (and terms) do *all* of the work themselves! The only hard part is building them- but that will be a lot easier if archives can identify and spit out (foreground flows, background dependencies, and cutoffs)- just like in the mother fuckin paper.



==========
Sun Feb 19 00:46:06 -0800 2017

merging compartments branch with matrix: what do we want to save from the last commit?

* README

* ecoinvent_spreadsheet: refine cache loading (which we will hopefully never have to use again)

* compartments and test_compartments

* .gitignore

* entities/__init__ :
+from .quantities import LcQuantity, LcUnit
+from .flows import LcFlow
+from .processes import LcProcess
+from .entities import LcEntity

Sun 2017-02-19 18:32:28 -0800

ditching pandas.... let's do it this way:

 * make a list of all the ways the pandas sheets are being accessed (there aren't many)
 * implement a new minimal wrapper for xlrd that emulates them.
 
read_excel is used three times:
 - to read 'activity overview'
 - to read 'elementary exchanges'
 - to read 'intermediate exchanges'

'elementary exchanges' ==> _elementary

  _elementary[unitname].unique().tolist()
  _elementary.iterrows()

basically all I need is an iterrows

Sun 2017-02-19 19:45:51 -0800

Well, that was surprisingly easy. Disappointing note: ecoinvent_lcia generation workflow is distressingly out of date.


Sun 2017-02-19 20:39:52 -0800

ok- ecoinvent_lcia generation seems fine, actually.

==========
Wed Dec 21 19:13:07 PST 2016

Need to do some serious work on this shit.  Code is flung all over the place, all crazy. I need to dig through this with a pickaxe.

#1 - Compartment Manager-- that was some great (if not test-driven, then) test-supported redesign of the compartment handler.  The question is, where does that live?

The ForegroundManager has a ton of inspection processes, like compare_allocation, inventory, elementary, and so on.

The ForegroundManager also is the locus of saving and loading state files, even though those files all get saved and loaded elsewhere (?)

There's the catalog, which is a collection of archives; the archives themselves; the flow database;;; the background lookup; the foreground lookup;; the fragmentt builder


there are too many pieces. all this stuff needs to be reworked.



Wed 2016-12-21 19:26:32 -0800

Really, right now the ForegroundManager is really a WorkspaceManager-- its sole definition is a working directory.  Then inside that directory are the following files:

 - entities.json -- flows, quantities, and processes that belong to the foreground
 - catalog.json -- a list of data references
 - compartments.json -- a curated hierarchical list of compartments
 - fragments/ -- a directory containing fragment definitions
 

entities.json and fragments/ should be all that is required to host an antelope server.  In every respect, these are the deliverable products of the fragment building exercises.


# Archives

An archive is a self-consistent, monolithically managed collection of LCI data, that is, of entities.  Archives have a low-level interface

# Catalog

The catalog is the core fixture of the tool. A catalog is a listing of data sources, each of which provides information on the entities listed above.

A catalog is a list of data sources available to a project. It also includes some other project-specific information:
 * a customizable category manager, which includes flow compartments and process classifications
 * project-specific flow identity information, to aid in characterizing elementary flows (basically, identifying existing flows as synonyms for flowables known to the flow database; see below)




## CatalogRefs

CatalogRefs are some nifty emergent tools that come out of the catalog system.  A catalog ref refers to a unique entity defined by a specified data source.  The catalog allows a catalog ref to be dereferenced to produce the entity.

are strictly created by a catalog.  Their only constitutive properties are the catalog that created them, and an index + ID that can be dereferenced by the catalog (the index is a numeric index into the catalog's list of sources, the ID is the entiti


# LCIA

The approach here is that flows know their own characterizations. It is the job of a Flow Database (really a quantity database) to allow flows to characterize themselves.  This should not happen on the fly-- but rather, the flows in a given archive should all get characterized en bloc with respect to a particular 


# Life Cycle Inventory Model Design



## Fragments


## Scenarios

Scenarios are a list of changes to a collection of entities in order to demonstrate or a particular set of circumstances or assumptions.  In the original Antelope framework, a scenario consisted of five different types of parameter settings:

 * FragmentFlow parameters (changes to fragment exchange values)
 * FlowProperty parameters (changes to non-LCIA flow characterizations, such as energy density or composition)
 * Dissipation parameters (changes to how compositions are released into the environment)
 * Emission paraameters (changes to non-composition derived emissions)
 * LCIA parameters (changes to characterization factors)

In addition, there was the intention to implement substitution parameters, where a fragment termination could be changed under different scenarios.  This was complicated because of the way the fragment structure was stored and was never completed.

In the new framework, the objective is to support all the same types of parameters, although the mechanism for doing this is not so clear.

Fragments store fragment flow parameters inherently, and compute balances during traversal.  LCIA parameters and Flow Property parameters (and the deprecated composition parameters) are really just parameterized characterizations.  Dissipations are a special type of exchanges, so both dissipation params and emission params are really just parameterized exchanges.  So the challenge is merely how to store these in the characterizations and exchanges themselves, which really comes down to serializing and deserializing them.

Which can be fairly easily unit tested.

When it comes right down to it, unit testing is the secret to the whole refactoring project we are undertaking right now but it's HARD, and part of the reason why it's HARD is because the code has no testing whatsoever at the present time, and so there is no way to tell (other than myself sitting and thinking hard about it) whether any given change is going to work.

At the end of all this, the code will be substantially improved.  The question is-- the problem is-- how long will it take to get to the end of all of this? I'm already behind on the Patagonia Virent annex, and I'm arguably behind on the AUOMA project, which from an lca-tools perspective I *haven't even started yet*.





==========
Tue Jan 10 14:18:02 PST 2017


Exchange refactoring.

Allocated exchanges are a terrible abuse of code.  Desperately need a test suite (read: a functional definition) for exchanges.  Right now the thing causing the issue is some stupid shit with validating allocated exchanges, where I assert the reference value for the reference flow must be nonzero, and the non-reference value for reference flows must be zero.  That's causing problems for processes that list their own reference outputs as inputs, which is not a problem *as long as the nonreference factors get added together* when the matrix is constructed.  I'm sure this is what ecoinvent does.  well, who can be sure?

anyways-- it's coming up at all because I monkeyed in these runtime assertions to validate the allocated exchanges since I never bothered to define their functionality with tests.

Can we confirm this is the case in some other application?

Yes- in the APOS case, the heat and power co-generation process has the same exchange listed [the one causing the error] (twice; once 0) as an output and twice as an input.

so I am going to simply ignore the errors for now, and fix on the refactor.



Tue 2017-01-10 14:39:38 -0800
seems to be working. FYI, refactoring exchanges into a dict from a set has also eliminated the slow performance, even from zip (somewhat: 5000 processes in 53 sec; and counting)
125.66 sec to load 12966 processes.

ok, heading to campus


==========
Wed Jan 11 22:42:17 PST 2017


Proposal: mush all outputGroup 0 + 2 flows into reference exchangess on initial Lc load.  that would mean diluting the meaning of reference exchanges (but they're already allowed to be multiple)


need tests! need a spec!

Here's what a process inventory should be able to do:

I = ProcessInventory(catalog_ref)

I.




Here's what I would like to accomplish:

LC = LcArchive(catalog)  # e.g. from json

p = LC[process-key]

p.exchanges() should yield exchanges

p.exchanges(flow-ref) should operate as (and replace) p.allocated_exchanges()

p.exchange(flow-ref, direction[=None])  # all instances
  basically FirstOrDefault()
  if query returns multiple results, raise exception; StopIteration returns None.

p.exchange(flow-ref, ['Input'|'Output'])

p.reference_entity is a set of exchanges

p.references() should yield references


x = next(p.references())

x[ref-flow] returns exchange value under allocation for ref-flow

we should strive to make allocation specified as simply as possible at the process level
but exchanges, if they store it, should also know (?)

exchanges have got to be thought of as observations

So x = an ExchangeValue() which can be specified statically at invocation [as a dict]

x.value is the somehow-designated (first observed) exchange value- should be immutable.  But all exchanges should be AllocatedExchanges, in the sense that all exchanges should have dicts of values. of observations.  which could be e.g. node terminations.

the million dollar question is whether I need to preserve the outputGroup designation-- and I think no.  The question has got to be, how am *I* using it?

Currently, ecospold.py raises an exception if it sees multiple references.  ecospold2- wow, ecospold2 just calls them all outputs and grabs the reference from the filename.  If you want a separate reference you have to load a separate file, I guess.  but unlinked processes? it doesn't know. since it ignores that part.

what about the serialization? no harm, no foul- ecospold v1 processes will never have multiply-valued exchanges; ecospold v2 processes (unlinked) currently are also all single-valued, and (linked) the change should have no effect on the reference flows.

I currently don't use it in the foreground-- (where do I query ecoinvent processes? for LCIA, where the reference should maybe be made mandatory)  but then in cases where I do expect a singular, I can catch that according to the spec.  In building fragments I just grab all the intermediate flows.  which is to say, I ask the compartment manager. that would include all reference flows.

so it's resolved-  ecospold loaders should mark outputgroup 0 and 2 as reference flows.  That solves half the problem of pre-loading uslci.

ecospold2 loaders should look at the byproduct classification

p.reference()
  yield the first or None; raise if multiple

so what do I do if I catch that?  when would we do it? only if not specified. on query it's known - term_flow is known - so it's not a problem.

And the exchange should simply return the value for the term_flow.

okay, so we have our refactor.  Then loading exchanges should simply be registering observations.  much simpler.

that's all there is to it.  If a flow has extra references defined- fine.

anyways.... how do we use this to build
