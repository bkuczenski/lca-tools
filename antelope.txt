==========
Thu Mar 22 13:25:52 -0700 2018

In our new architecture, we have a number of different pieces to develop:

 * A web infrastructure for providing information on (a) individual studies and (b) databases (open source, public, backend, NAL supported) [Antelope v1/v2 server]
 * A research infrastructure for creating and reviewing product system models (open source, public, frontend + backend, UCSB supported) [js model editor; interacts w Av2 server]
 * A data infrastructure for intelligent access, retrieval, and review of data (closed source, commercial, frontend + backend, vault.lc) [js data reviewer; interacts w Av2 servers and proprietary backend [e.g. graph / tag db]]
 * A free model interactor (open source, public, frontend, interacts with Av1) [CalRecycle FrontEnd]
 * a premium model interactor + publisher

Thu 2018-03-22 13:59:30 -0700

The security model for the Av1 server is unclear (as ever).

How is the Av1 server used?

 - Study authors use it to publish studies to specific audiences, or to the general public
   = study content should not be available to someone who is not authorized by the study creator

 - authorized users may create their own scenarios, which *could or could not* need to be stored on the server
   = scenario specifications and results should not be available to people not authorized by the scenario creator

In the basic (non-privacy-preserving) imagining, the av1 server is housed in a container which is enclosed within a private cloud.  Users access a wrapper service which handles authentication and forwards authorized requests (internally) to the servers that can answer them.
 * here the wrapper service is aware of the contents of all requests and presumably has access to all resources in the internal cloud
 * this is not desirable if people want to use the service to share secret models with collaborators

Thereby, the privacy-preserving case requires that the av1 server be able to negotiate authorization with users directly.  This means that the study author needs to be able to specify access rights in a way that enables a 3rd party (vault.lc) to adjudicate access without being able to obtain access.

Thu 2018-03-22 15:23:43 -0700

OK, so the way I think this works is:
A: Study author; owns secred data
C: Client; granted authorization to view data or results
V: vault.lc; provides hosting and auth adjudication
R: repository to contain secret data; owned by hard private secure storage
 + A must have exclusive access to write to R
 + A must be able to mediate access to read from R (how?)
S: Antelope V1 server instance; created by V

0. A creates secret repo R, including an auth specification with:
 - R contains distinct token per authorized client C
 - R contains mapping of token to authorized views
 - stored non-volatile in R and can be updated, replaced, or revoked by A

1. A registers address of repo @R with vault V [case 0: provides $$$]

2. V instantiates Av1 server S, gives it @R and id of A
 - S generates pubkey pair, provides pubkey K_r,pub to V

3. S attempts to access R; A mediates access (how?)
 - A grants persistent access (how?)
 - R must be able to push out updates to S

4. A gives C her dedicated token
--- A no longer needs to participate, until a new Av1 is required

5. C contacts V with @R [case 1: provides $]
 - V constructs JWT with prudent expiry and signs it with K_r,pub

6. V provides @S and JWT to C 

7. C transmits request and JWT to S; supplies token as query param (alt.: uses token to establish session)
 - S validates JWT: ensures 
 - S validates query token
 - S answers request

Where do scenarios live? if S is stateful, there needs to be a way to make them persistent across instantiations
if they live on C, then S still has to be stateful, unless the full param list is specified with every query (seems wasteful)

I guess the easiest thing is for C to replicate the model and perform its own traversals to implement scenarios

Anyways, it's clear that the flask app needs to be able to receive and validate JWTs.



==========
Wed Dec 06 10:03:19 -0800 2017

I have come up with at least five different things that "Antelope" means:

 * the existing antelope v1 CLIENT interface for a finite set of integer-enumerated entities included in a collection of fragments

 * the SERVER for that, which may or may not be the same as the fragment builder

 * the antelope v2 server, which is meant to be a data clearinghouse that sits on top of an LcCatalog and can translate semantic.ref/entity/query into serialized results

 * the antelope v2 CLIENT, which allows me to talk to a remotely stashed ecoinvent so that I don't need it on my local machine

 * the antelope node server, which acts like an antelope v2 server for a single semantic endpoint and MAY or MAY NOT include Qdb capabilities.

On top of that, there are two persistent issues that are causing me anxiety moving forward:

 - is_elementary and the compartment manager in general was always a stopgap (written in the West Branch library one morning in 2016?) and could be either (a) better aligned with synlist or (b) part of a newly reimagined graph-based Qdb

 - flows properly being flowables, compartments being shifted to EXCHANGE TERMINATIONS, which would be a radical reimagining of pretty much everything.

I'm really excited about reducing flows to flowables, but it would break compatibility with just about everything, starting with the existing antelope v1 (not to mention the J Cleaner paper) which steadfastly applied a category to every flow / declared all flows have compartments. [J Cleaner fairly situated compartments as distinct semantic entities]

So-- if compartments are distinct semantic entities-- do we need to store them in archives?  If compartments are terminations, does that mean they are really processes??

NO, they are not processes, or if they are they are the mothers of all multifunctional processes.

It wouldn't be meaningful to call a compartment a process, because in order to do LCIA on it the process would have to be allocated (by CF) across all flows into that compartment that have impacts, and suddenly we are right back to having an exploded set of entities.

How would this even work? everything would have to get reimagined.  Background emissions, which are presently flow + direction, would need to be flow + termination (with direction implicit??? )

right? there's a deeper problem- the implicit natural directionality of compartments, of contexts. we've already had to start dealing with that in characterization.set_natural_direction() [which must be supplied a compartment manager] -- well so we've already acknowledged it. that's not to say we've solved it.

I think I need to spend some time thinking about how Qdb is supposed to work in this brave new world


Wed 2017-12-06 11:59:40 -0800

Back to antelope servers.  We're going to keep the current system of having flows be about paired flowable + context, but we want the antelope interface to be forward thinking.  So let's go through the API and make sure that it makes sense.

Well.. api.md is rather hopelessly out of date.  It can be simplified a lot.

Wed 2017-12-06 13:18:06 -0800

Worked on this for too long... FWIW I really need to get going on Swagger.  I am putting this down, eating some food, and then doing my important TODO for the day.


==========
Fri Jan 05 09:33:43 -0800 2018

Long month...

Swagger spec for antelope v2 is coming along great--

reading about JWT right now as the most likely form of authentication for the resource to use

Good discussion of shortcomings, mainly that there is a single secret key (in our case per resource) that can be compromised:
https://medium.com/@rahulgolwalkar/pros-and-cons-in-using-jwt-json-web-tokens-196ac6d41fb4

Also helpful comparison of JWT and OAuth, which are totally different:
http://www.seedbox.com/en/blog/2015/06/05/oauth-2-vs-json-web-tokens-comment-securiser-un-api/

lots of discussion etc etc:
https://auth0.com/blog/ten-things-you-should-know-about-tokens-and-cookies/
http://www.bubblecode.net/en/2016/01/22/understanding-oauth2/

https://auth0.com/blog/critical-vulnerabilities-in-json-web-token-libraries/

These people are (a) self-styled crypto badasses and (b) dead-set against all things JOSE
https://paragonie.com/blog/2017/03/jwt-json-web-tokens-is-bad-standard-that-everyone-should-avoid

All that said, JWTs seem like a perfect (at least near-term) solution to our particular security problem, particularly public-key-based JWTs, because they allow the resources to autonomously validate requests without any communication with the server.

The problem: if the tokens are ever supposed to be limited-use, then EITHER the resource has to check with the auth server OR the resource has to become stateful. There is no third option. the TOKEN can't be stateful.

Since we're adamant about resources being stateless, and since we ALREADY operate an auth server, I think we should just go that route.

The JWTs should have three different types:

 - unrestricted access with a privacy level (integer?)-- strong expiry-- server may still need to be contacted for revocation checks
 - metered access (notifies auth server per query for billing-- server returns 200 OK or 401 if revoked)
 - limited access (asks auth server per query for sufficiency-- server returns 200 OK or 401 insufficient)

Both of the latter two do away with the "federated" benefit of the JWT, but they preserve query privacy.

Here's how the system will work:

PLAYERS:

AS Authentication server: vault.lc
RP Resource Provider: ecoinvent.org
RC Resource Container: stateless Antelope V2 server: eiv3.2.apos
UU User: Ralph Fishnet
CA Client application: antelope container

STAGES:

Stage 1. Initialize resource
Stage 2. Authenticate session
Stage 3. Query resource

STEPS:

Stage 1: Initialize Resource

 * RP approaches AS with data to be made available as a resource
 * AS creates RC with one-time session key
 * RC creates asymmetric keypair
 * RC transmits public key with session key to AS

public+private key pair for RC
 $ AS creates stateless RC and seeds it with the "public" key which remains secret
 * AS deploys RC

Stage 2: Authenticate session

(mode a: user is already an RP licensee)

 * UU approaches AS and logs in to RP via OAuth2
 * OAuth2 grant establishes UU's account status
 * AS generates an unrestricted JWT with a 1-day expiry
 * AS provides a resource file to grant CA data access to RC using JWT

(mode b: user is a vault.lc user with pay-per-use for protected resources)

 $ monthly billing
 * UU logs into account and invokes CA
 * AS provides resource file supporting index interface to RC
 * AS provides resource file supporting data proxy interface to RC

(mode c: user is a vault.lc user with an ecoinvent limited-use)

 $ during monthly billing, AS generates a limit JWT with a 1-month expiry and a query limit
 * UU logs into account and invokes CA
 * AS provides resource file supporting index interface to RC
 * AS provides resource file to grant CA data access to RC using limit JWT
 * AS provides resource file supporting data proxy interface to RC

Stage 3: Query Resource

(mode a: user is already an ecoinvent licensee)

 * UU submits query
 * CA performs query to RC, using unlimited-use JWT (DWR! not revocable!)
 * RC receives query; decodes JWT; validates permission; [optionally increments auth server]; answers query
 * CA receives query
 * UU is happy
 
(mode b: user is a vault.lc user with an ecoinvent pay-per-use)

 * UU submits query
 $ CA performs query; proxy negotiates payment
 * proxy returns a JWT
 * CA forwards query with JWT to RC
 * RC receives query; decodes JWT; consumes token [notifies auth server]; answers query
 * CA receives query
 * UU is happy

(mode c: user is a vault.lc user with an ecoinvent limited-use)

 * UU submits query
 * CA performs query
 * RC receives query; decodes JWT; validates permission; increments auth server; answers query
 * CA receives query
 * UU is happy
 - if limit is exhausted, CA removes resource containing limit JWT; go to mode b



RC Constructor:

To create an RC, I need: a one-time key, an auth server...
Thu 2018-01-11 10:01:04 -0800
see notes in spiral notebook.


==========
Thu Jan 11 13:34:46 -0800 2018

Components required for an Antelope V2 Server:

 - AntelopeV2Server - main constructor
   :param auth_server:
   :param auth_pubkey:
   :param privacy:
   :param qdb_server:
   :param archive_init_args:
 - AntelopeQuery - replaces CatalogQuery
   - new QuantityKey - replaces QuantityRef - drop-in as argument in call to load_lcia_factors()
     :param qdb_server:
 - flask config + route-to-query mapping

I think that could be more or less it.

Thu 2018-03-22 13:25:41 -0700

This is updated in deadtree format in journal
