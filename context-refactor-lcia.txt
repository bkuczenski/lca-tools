==========
Fri Oct 25 09:41:27 -0700 2019

Moving right along.. yesterday we took 60% out of the computation time for LCIA, mainly by reshuffling the quantity interface to avoid redundant argument processing, but also by tracking down a design flaw in _canonical_q that was requiring str(qty) [which requires at least two get_item() calls for refs] to be called ALL THE TIME... I spent an embarrassingly long time to bring about 15 SLOC changes that were in retrospect very simple (see 646e859) (but the restructuring, which did most of the work, was dfa7f95)

Fri 2019-10-25 17:56:22 -0700

Now I have squandered an afternoon tracking down exchange relation "performance issues" (meaning discovering the terror of LcProcess.reference() )

Here's the stack:
89.6 --> 78.0 traverse_term_exchanges (9.6 s update component graph ~2s in glue / from_index)
Of that, 42.6 exchanges.__getitem__ 42.62 sec / 8.526 tottime : 1018374 calls
of which process_ref.exchange_relation() 1018374 calls but 38.24 / 2.646 tottime

but anyway that is a big bit-- line 653 is probably called 792k times- plus probably subsidiary calls beneath => 1018374/2016979 so some of that could be double counted

traverse is 6.366 foreground

leaving 29 sec unaccounted for:
	3.2s terminate
	3.3 + 2.5 = 5.8 product flows + emissions
	1.2 set_lowlink
	=12.0 handling
	==
	-16.8 in background_engine (9.5s in foreground hmm)

	===
	12 sec

78.0: 6.366 foreground
      14.1  635: process_ref.inventory
      42.62 653: __getitem__
      3.2   684: terminate
      1.2 add_emission
      1.8 add_cutoff
      1.3   698: check_product_flow
      1.2 set_lowlink
      1.5 add_interior
      ---
      73.3

Plus glue. So the big culprits are inventory() and exchange_relation()
and they are both dreadful.
but they work for now and will wait until later.

strict task: BUILD FRAGMENTS

      
      


	

Tracked down major problems:
 - process_ref.exchange relation takes 38 out of ~88 for flat background [which is about 4x slow]
 - ExchangeValue.make_ref itself takes 11 s, and why are we even making exchanges?
   = need a proper ExchangeRef which a processRef can trivially make (like RxRef) (in fact one is a subclass)
 - also, process.reference(flow), which should be inexpensive, is 9.1 out of 88 sec
   = shockingly reference() starts out with find_reference which is incredibly costly
   = references() also should not take an argument, but in fact does what reference() should do

==========
Sun Oct 20 20:17:03 -0700 2019

Setting up ILCD LCIA for CATRA project. Two cascading problems:

 1- despite having indexed the archive, listing LCIA methods seems to require each of them to be loaded
 2- duplicate characterization factors are not accepted even if strict_clookup is False

We'll take them in turn:

1. so right away we are running get_canonical() but that actually seems like a good idea (..?)

get_canonical means, get the ref that points back to the authentic version in the LCIA db
but that in itself shouldn't require the factors to be loaded
do we just not know how to tell whether or not the factors have been loaded?

when does import_cfs get called?

That's it. That's the only time. So we expect to load the factors when we add to tm.

I guess that makes sense. so the question is whether we need to get_canonical here?
 - if we don't, what is getting returned ?
 - let's see.

I think the secret is to not require make_ref to return a canonical quantity. get_canonical is declared to load factors, but that is not required to view a ref.
when needed, get_canonical should already be getting called so this should be error-free.

Sun 2019-10-20 20:37:20 -0700

Nope that doesn't work, because the reference that came back is not canonical, so it doesn't know how to do lcia.  The solution must be to delay loading factors. But we can't do that naively because the actual entity that knows how to load the factors is not the masqueraded one that is "canonical". So we have to keep it around.

(note: the only time this was tested was in test_uslci so that is not auspicious)
(but at least it was caught by an existing test)

Sun 2019-10-20 21:45:56 -0700

OK, that seems to be working- we simply defer loading the factors. now we are more or less cooking with gas, except we are punting on that duplicate characterization situation.



==========
Tue Jul 16 15:56:29 -0700 2019

Time marches on and I get further and further behind.
Right now, ostensibly, my task is to get the MFA working but instead I find myself pondering flows and flowables and flow interfaces and entity refs and synonyms and quantity terms.  My entities are hopelessly overengineered, but:
 (1) fixing them should not block progress on the CATRA project
 (2) fixing them requires clear thinking and not hasty hacks.

So I am going to rollback all the current changes, and take on the entity interface later in time.


==========
Sun Jun 02 22:36:42 -0700 2019

Ok, all that is fixed and now-- the 13th hour-- I am poised at the threshold when I see another problem that doubtless has a solution, though I can't immediately see it:

 getting the fragment built; doing the traversal; traversal fails on flow conversion
 Investigating, I see that the term_flow, which is derived from the RxRef of the term node, has a reference entity whose query is not masqueraded. It's an authentic local.uslci.olca reference (i.e. its query origin is local.uslci.olca).

But I see that it's a catalog query, and not a basic query, so there is hope.

Two ways forward:
 1- ensure that RxRefs built from catalog queries have their flows' reference entities masqueraded
    -- but how deep does that problem go?

 2- throw in a get_canonical in the flow_conversion

The latter seems irritating- since presumably traversal will happen a lot more than construction.  Plus we already call get_canonical too many times (maybe the wrong times?)

Sun 2019-06-02 23:19:29 -0700

The former turned out to be a one liner (plus a debug)
The answer: it's shallow. Just use query.get_canonical(reference_entity) to make the quantity ref.

And we now have running scenario-ized fragment traversal and disclosure.

no small feat for 2h on a Sunday.




==========
Fri May 31 11:51:29 -0700 2019

OK, now it is the 12th hour.

WE got everything passing, except we are still uncovering new ground.  Specifically: in order to be able to save foreground characterizations, we need remote quantity refs to be present in the foreground entities list.  This is fine, EXCEPT that the quantity refs available to the archive are in fact MASQUERADES hosted by the catalog and pointed to local.qdb.  This is fine, too, EXCEPT that upon initialization the local qdb doesn't know how to retreive the original quantities, because the masqueraded information is lost.

I see a couple of paths forward.

First, I tried altering the serialization to include the original authentic origin-- that worked and allowed the fg to initialize, but the new catalog ref somehow worked its way




==========
Thu May 30 12:58:29 -0700 2019

Well, it wouldn't be an antelope project if it didn't include a desperate 11th-hour discovery of a coding design failure.  In this case a somewhat indeterminate situation with flow characterizations.

Basically: several things are true.
 - catalog.create_foreground needs to return a query to a foreground resource, NOT a foreground impl
 - foregrounds need to intrinsically include quantity interface
 - coding bug in lcia_engine serialize that was wrongly filtering out canonical quantities that did not match the origin (but all canonical quantities will have 'local.qdb')
 - LcFlows cannot implement profile()
 - LcFlows DO not implement characterize()
 - general lack of protocol for characterizing flows (hint: DON'T use external_ref)

In Term Managers, flows are known by flow.name and flow.link, and those ALONE.  In Lcia Engines, flows are known by their synonyms, which include those plus cas number and synonym properties.

When we are characterizing flows while building a foreground, we should use the foreground's quantity implementation to do it, mindful of the fact that foregrounds share the catalog's term manager (LciaDb)
 - first we should be sure that the flowable is already known by the LciaDb, since the foreground DOES call _add_to_tm()
 - but, we must remember that (for characterizations), external_ref is the wrong key. link is the right key.
 - BUT, we need to make sure that the traversal-termination-flow quantity conversion machinery has a comparable expectation.  What does it do?
   = forward: term_flow.reference_entity.cf(_parent.flow)
   = reverse: _parent.flow.reference_entity.cf(term_flow)
 The cf just goes straight to the quantity interface, where it ultimately uses _get_flowable_info.

It turns out _get_flowable_info is rather peculiarly implemented.  Here's what it's supposed to do: Given whatever the user provided in terms of flowable, ref_quantity, and context, come up with canonical values for all of those things.

Here's what it actually does:
 - if (and ONLY IF) ref quantity or context is lacking, try to retrieve a flow entity based on flowable. If successful, flow.name is taken (which is appropriate since .name and .link are the two guaranteed terms, though maybe .link would be more robust).

If unsuccessful, or if both quantity and context are provided, whatever was given as flowable is just passed right on.  So _get_flowable_info does not directly parse the flowable argument.

What we should do instead: just check to see if it's a flow first.

Last detail: for current code to work, methods currently defined in the foreground implementation but not in the interface need to be moved to the interface.  This is fine because part of the outcome of this project is supposed to be defining the foreground interface. They include:
 - split_subfragment (with replacement)
 - delete_fragment (with error / termination checking to be handled in the future)
 - save

Noted foreground interface methods that have not yet been implemented:
 - observe
 - set/unset balance flow

And hypothetical operations that have not yet been defined in the interface or the implementation:
 - find_or_create_term (maybe outmoded by fragments_with_flow)
 - terminate fragment (maybe unnecessary since the fg interface returns actual fragments and not refs)
 - build fragment from term (add_child_flows)
 - build forest from [foreground | traversal]

Thu 2019-05-30 11:21:02 -0700

OK, where are we at?
 - One, LINKS ARE NOT BEING ADDED TO FM for some fucking reason
 - Two, the whole thing is fucked because many flows (with different characterizations) have the same NAME and so are SYNONYMS.

Remedies: either fundamentally change how we create flowables, or change how we are assigning flow names.

FUK.


Thu 2019-05-30 12:59:04 -0700

OK, here's the situation.  The process for adding flowable terms to the Term Manager is fukkokked.  Untested, poorly defined, clearly broken for first real-world use case.  Time for some test-driven development.

Currently, terms are added to _fm in the following places:
A * in _create_flowable(name, *syns)
A1   = called from _add_flow_terms, in zero match case, to create new entry for all terms
A2   = called from _add_flow_terms (via _add_pruned_terms) to add new terms to new match
A3   = called from add_characterization, to create single-term entry in case none exists
B * in _add_flow_terms(flow):
B1   - in merge|prune mode, in single-match case, to add new terms to existing match
B2   - in merge mode, to add new terms to merged entry
   = called from add_flow()

So A1, A2, B1, B2 all come from _add_flow_terms; A3 is an exceptional case.  So we need to refactor _add_flow_terms, which is ONLY called from add_flow().  All of our test cases should use add_flow()

What do we want to do:

 * For elementary flows, we want to reduce a large number of flows to a smaller number of curated flowables.  Here we want to merge aggressively, but then, curate. This is also not a normal operating mode.

 - In this mode, if we find one match we automatically throw in with it, and we only deal with conflicts if we find two or more matches.
   = the merge strategy means collapse two (or more) different flowables together, with the attendant challenges of remapping all the CF lookup dicts
   = the prune strategy means prune off all the new terms into a new flowable and return that. this also begs curation
 - This mode should be entered when we are importing characterization factors and we find a context that we identify as elementary.  For Term Managers, let's say any flow that has a non-null context should merge this way (which- merge or prune?)

 * For intermediate flows, and especially foregrounds, but generally any flow that has no context, it is important to preserve the exact flow information, so we should add flows in a 'distinct' way.  This means we use an existing entry only if all terms match it; otherwise we follow the 'prune' strategy even if number of matches is only one.
 - realistically, this means the flow's link is its only guaranteed identifying factor.
 = We should be using the link to retrieve characterizations whenever it's available.

Thu 2019-05-30 14:45:21 -0700

OK, so now it's 3/4 of the way through the day. I haven't TOUCHED the EPA project which is due TOMORROW.  I've definitely fixed the problem with links not loading (hint: remove a single underscore, in entities.py, to use origin.setter, to trigger flowable update.  I've also added the 'distinct' merge strategy.  (but I've not tested it nor any of the other merge strategies)

Now I'm on the LAST part- which is using flow.link instead of flow.name-- I said to "retrieve" CFs, but it seems pretty important to also use it to "assign" CFs.  The assignment is specific; the LciaEngine generalizes it-- again, using the curated flows-- so how is this supposed to work for LCIA? If I create all my CFs using the link, then I need to import flowable links before I can import CFs, or else all the CFs will just be siloed in their own private flowables.

I can't possibly include every possible link as a synonym for every canonical flow-- minor versions and the like-- so that doesn't work.

What's the theory of operation for adding and retrieving CFs? (what a great thing to be thinking about with 2 hours left in the last full day of work on the EPA project)

It comes down to the two different modes of using the LciaEngine.  Mode 1 is using it as a storehouse to assign and retrieve flow profile information (as in the EPA project).  Here we want both the assignment and the retrieval to be as specific as possible, so we should use the link both times.  We do NOT have/want the expectation that the LciaDb will find a near match in this use case.  This use case corresponds with the use of the 'distinct' merge strategy.

In Mode 0, which is also the original design mode, the LciaDb is an interoperator which is meant to smooth over incidental differences in favor of curated flows.  In this case... the retrieval mechanism should map a specific query to a curated flowable-- which means, YES, the source repository from which the query flow originates needs to FIRST register its flow synonyms with the LciaDb, so that the link from that query will resolve to the curated flowable.  And that should be done with the source repo for the characterization as well.  That means we can't get away with just using flowables just yet- we need to write a mechanistic process for mapping links to flowables. and we need to converge on using links for everything.

That is a task for later. For now we are in mode 1.

But in general, in ALL CASES (which is what "in general" means), if a flow's link is available to identify a flowable, USE IT.  When assigning characterizations or retrieving them.

Right now we have the problem where half the time, via the quantity interface, we are using flow external_ref, but there is no simple way to distinguish between an external ref and a link without doing complicated and highly contingent string manipulations.  Let's look closely at the quantity interface and see where (if ever) external_ref is okay:

get_canonical-- here external_refs are supposed to be general because there is a small number of quantities.  _quantity_terms explicitly includes external_ref.

characterize-- this is the tough one. circle back.

quantity_relation,

Fri 2019-05-31 09:08:21 -0700

OK, part of the problem is this principled decision for a term manager not to know its own origin- so captive term managers SHOULD operate strictly on external refs.  but obviously that breaks down in the LciaEngine case.


so, argument: TermManager._flow_terms should be name and external_ref, LciaEngine._flow_terms stays as is.

BUT WHAT ABOUT _get_flowable_info? This is the gateway into quantity_conversions, which is the first point of entry for quantity_relation, profile, do_lcia, cf.

Well, one approach is to have get() handle either external_ref or link-- which it NOW DOES-- and just include get() in _get_flowable_info.
ok. done. maybe a bit costly. we haven't gotten to optimization yet. but we need to move forward.

flow.link is the canonical flowable in all cases.  The LciaDb needs to facilitate mapping an archive's links to curated flows, full stop.  This can be accomplished via flowable hints (though not in their present implementation).


==========
Mon May 13 16:31:57 -0700 2019

We are now noodling in context refactor as a dangerous prelude to even BEGINNING work on EPA- now 43 days overdue- because the prospect of having to write a USEEIO provider in the old master is so immiserating and because we want to make use of the new Qdb functionality to build fragments for EPA.

AND THAT BRINGS US TO: stupid shot-self-foot problem #1,648,341: in the interest of efficiency, the term manager no longer collects all the synonyms from flowables, only the name and the external ref (see commit 6b6dc49)-- THAT'S RIGHT! Because of shot-self-foot problem #1,414,233, which was the requirement that TermManagers have strict CLookups- or in fact, not even strict CLookups but dicts (are we even using strict CLookups at all? only by request on LciaEngine invocation) AND because ILCD reference flows (at least from 3.2) are horribly curated and included CAS collisions.

So now we are running into a problem that stems from shot-self-foot issue #1,234,569, which was the simplification of TermManager to store flowables in a SynonymDict rather than a Flowables dict (commit 26219e2) which was done for performance reasons, on the reasoning that: why should we bother with all of that when the whole purpose of TermManager was to learn terms that were specifically supplied by the archive, whereas the whole purpose of LciaEngine was to do elaborate term matching?

So, fine, except two things:
1- I get a twinge of regret when I see that the IPCC database now serializes flow names but not CAS numbers, so I attempt to rectify that by using an LciaEngine instead to generate the canonical IPCC set, only
2- now the SynonymDict is stored as Flowables and so it doesn't deserialize because of stupidity.

Now we can fix this easily, by hacking something in analogous to LciaEngine.add_from_json, which subs the old for the new (and it will have to be a hack in the superclass in order to comport with that exact hack in the subclass), or else we come up with a more systematic solution.

Every conceivable solution involves SOME level of hack:
 * making the _entry_group property of a SynonymDict non-private so it can be inspected
 * specifying the _entry_group redundantly in the client code (e.g. term_manager.py and lcia_engine.py)
 * doing a double-take and try: pop Flowables, except Key Error: pop SynonymSets

The REASON we are having this problem is.. REASONS we are having this problem are:
 - we are leveraging the SynonymDict's ability to automatically know the types of its serialized entries, for the EXACT REASON of preventing client code from doign what we are trying to do, namely de-serializing one serialized type as a different type
 - we are trying to capture LciaEngine functionality in a TermManager

Mon 2019-05-13 18:35:59 -0700

Solution: enable renaming of _entry_group and force all to Flowables.
Mon 2019-05-13 18:39:47 -0700
done.

Mon 2019-05-13 21:52:17 -0700

OK, on to testing ecoinvent in context refactor via variability_jlca notebooks... cutoff bg built, now doing APOS. of course, this doesn't mean the LCI is correct.. to say nothing of the LCIA.. ugh I don't even want to be doing this.

Mon 2019-05-13 22:04:30 -0700

Unittest fails with 0 LCIA scores. plus loads of debugging info incl. 15,000 "Gone canonical"s.

I'll take this up later maybe.

Tue 2019-05-14 11:11:22 -0700

OK, so now I am wading into the ecoinvent lci unittest I wrote almost a year ago- discovered that the test would not initialize because there was no LCI 7z resource (which I had deleted to save disk space) and found (with some gratification) that simply downloading the file and re-attempting was successful in detecting and adding the resource.

Now a problem with a quantity conflict in _extract_and_reduce_lci which I completely do not have the patience for.

Tue 2019-05-14 11:33:05 -0700

OK, so there is some meat here.  The frankenprocess we have constructed has a reference flow that's an RxRef- so its constituents, namely the flow's reference quantity, are all refs.  The process itself, though, is a literal entity and not a ref, and its exchanges are added directly... but.. the flows are drawn from the inventory() call which is called on the process ref so they should be refs and not entities as well.. except they're NOT! the interface does not call make_ref on exchanges, presumably for performance reasons.

Now we have another conundrum.  We either need to change the RxRef to use authentic entities instead of refs, and save an archive of authentic entities, or we need to change the inventory() call to return refs instead of entities.  The second choice SEEMS better, but it is a thoroughgoing change and who knows what effects it will have- since we haven't gotten as far as testing all that yet.  We are not sure whether entity refs will serialize in a way that allows them to be deserialized correctly- but I seem to remember some policy that was crafted in my head in which archives should not store refs.  So perhaps the solution is to de-ref-ify the flow and quantity as it is coming in-- except that would mean modifying the exchange object itself which we cannot do.

Really we should try it both ways and see if the solution works either way.  But who has time for that?

first let's investigate how the inventory call is SUPPOSED to work and see if it is working correctly.

Minor brainstorm: just add the make_ref call to the process_ref method, rather than the interface.  Not sure whether this is correct or not.

Tue 2019-05-14 12:13:58 -0700

Initial results: the archive serialized and deserialized just fine.
Note: somehow the quantities even de-serialized AS Refs! Don't understand that....
time for lunch.
Tue 2019-05-14 13:32:08 -0700
Nevermind-- the query was returning them as refs, but they are still native quantities.

Tue 2019-05-14 14:07:38 -0700

OK, we have hit the impasse- and as suspected, it is in the Background Engine.  The problem comes down to RxRefs not KNOWING their own exchange values, which is a problem in ExchangeValue.__getitem__ when computing self._value / item.value where item is a reference exchange (or, as it happens, an RxRef).

The REASON we did not want RxRefs to know their own values was because we want Index Interfaces to know reference flows without knowing reference magnitudes- i.e. for them to be purely value-free. Hence the InventoryRequired error.

The problem is that, now we are computing exchange values from Refs-- Refs aren't supposed to be able to do that ANYWAY. Computing exchange values is something the authentic process is supposed to be able to do, but not the ref. (WHY? our normative logic is getting ever more tortured)

I am whizzing through all these TERRIBLE ideas to fix this problem:
 * Exchange.make_ref() makes flow refs but not process refs
 * ProcessRef.inventory() calls make_ref for non-None ref_flow but not for None ref_flow
 * catch InventoryRequired in __getitem__ and do something different
 * once again allow RxRefs to remember/memoize values
 * allow process refs to memoize RxRef values

Our conceptual idea of what is an entity versus what is a ref has completely collapsed.  Is it a firewall? is it a convenience measure? nothing really holds up because the two objects have been redesigned and refactored to be more or less entirely equivalent. And HERE, in computing allocations and normalized exchange values, the last bastion of distinction between a process and a ref, is being attacked, and the entire reason for the existence of the ref is threatened. Why the fuck were we doing this anyway?

To recap: the reason for a process_ref is so that we can access remote resources as though they were local.  If that is the case, the error is in calling exch[rx] in the first case, expecting it to behave as though it were a local exchange, when in fact we are dealing with a process ref.

But WHY are we even treating everything as a process ref INSIDE the BACKGROUND ENGINE? Because we're giving it a query, which turns everything into a reference.

Really, the background should have privileged access to the archive when it is local-- but should still work when the archive is remote.  This means the getitem call is the problem.

Question 1: can we make it so that the objects seen by the background engine are processes and not refs?
Question 2: can we make it so that the exch[rx] access is seamless for both processes and refs, but still preserving the [notional] performance boost that comes from accessing __getitem__?

answer 1: when we run add_all_ref_products, if we had an archive we could ask for entities_by_type(process) instead of processes()
No, no, no, no, the idea that the fg is an index interface is FUNDAMENTAL.  Instead we need to work-around exch[rx] in a way that is more or less the same performance.

Tue 2019-05-14 14:35:05 -0700

AHA! a conjoined problem: LcProcess has no exchange_relation implementation!

==========
Fri Apr 19 10:51:10 -0700 2019

We are converging... but now there is this problem with allocation, and no immediate answer to the question of how it SHOULD work.

Here's what's happening:
Well, I don't know exactly what's happening.  But in both ecospold and olca, petroleum refinery is only getting allocated to products native in mass; CFs are getting loaded into the captive term manager, but presumably because of context specificity, they are not being found by cf()- even though they should be, since in the allocation method the literal flow object is being used...

also btw, the unit conversion CFs are redundantly added for every flowable AND every context in which they appear.  by flowable it is not clear how the current architecture could avoid that, but by context it [maybe] should?

Fri 2019-04-19 12:19:12 -0700
ok, so we monkeyed around with quantities so that the ecospold engine could add unit conversions to them; now we have a bizarro problem where the mass's quantity implementation points to the LcIndex archive, whereas the CFs are loaded into the Ecospold archive.  Serious SMH moment here bcause again everything is at risk of crashing down and/or being futile and useless.

Fri 2019-04-19 12:47:15 -0700
We seem to have solved that problem by disallowing the index to generate quantity interfaces, and then by catching InterfaceErrors.
Now we have progressed up to the point of:
 * traci et al need context hints (e.g. air -> to air)
 * ecospold et al need quantity hints

and now I am needed downstairs

Fri 2019-04-19 13:57:50 -0700

Real quick: needed:
 x configurator: add context hints
   = figure out general solution to context hints
 x configurator: quantity + flowable hints
 * OLCA - figure out why the q_dict is getting unity conversions
 * ecospold2- add flowables to canonical set
 * construct flowable set from scratch
   - traci
   - figure out current diff from traci
   - ecospold2



Tue 2019-04-23 01:22:05 -0700

USLCI tests pass. and made a discovery about NullContext:
 - NullContext results from a definite context query that was not recognized
 - NullContext in the database matches any query that wasn't matched by a non-null context
 - NullContext as a query matches nothing except NullContext

tomorrow: look into calrecycle; reproduce variability / ecoinvent.

Tue 2019-04-23 14:12:17 -0700

current: finish reviewing uses of tm[getitem]






==========
Fri Apr 12 14:12:12 -0700 2019

Big Fucking Mess, part 3

We now have three big fucking messes, with nominal paths to resolution for == basically all of them, but with costs.

First is the context-matching problem I articulated at cob yesterday.  During the evening I rationalized the view that I am *expecting too much* of the resource infrastructure- and in fact my design is consistent with this view.  A resource is supposed to arrive at the catalog *already configured*. Obvious problems with configuring a resource after loading it into the catalog can be averted by designing a *configurator*, which possesses its own captive LciaDb, to validate an archive, install term mappings and other config, and then *ouptut* a resource JSON object for delivery to a file, a catalog, or a resource server.  This is good because the configurator, not the catalog, is the right tool to assess new archives and clean them up. Required tasks:
 * write the configurator- enable it to proof-check an archive against the LciaDb in 3 dimensions of quantity, flowable, context
 * add a config interface to basic archives
 * generalize context_hints to deal with quantities and probably flowables as well

Second is the problem I encountered last night when I started digging in, which was that quantities were *still* not synchronizing correctly, and this is mainly a problem with reference quantities.  We load CFs from a foreign archive and, to save time, we insert them whole into the _q_dict. But that means they bring their native ref_quantities with them.  The obvious first solution is to duplicate the characterizations in local.qdb, except that raises the problem of synchronicity- if you then add CF values to the foreign one, they won't show up in local.qdb, whereas if the entities are multiply referenced, they will.

This is operationally a problem because the CF is used to generate the QRResult (with Characterization.query()) and so it installs the foreign ref_qty, which then confounds ref quantity conversions and (more crucially) LCIA results, both of which test for equality.. what we really want is to test for canonical equality, but (a) we don't have access to get_canonical everywhere and (b) that would be really expensive.

(It's fair to say that THIS problem would be solved if we were using a giant graphdb instead of a bundle of entities to store CFs)

So what do we do?
 1. We could add a param to Characterization.query() that substitutes a canonical qty for the native one- this turns out to be irritating to implement but maybe best
 2. we could replace Characterization's ref_quantity with a canonical one, but that is problem because it's used for reference-checking and also in the hash
 2a. alternatively, we could masquerade the CF's ref quantity internally to the CF, but that seems heavyweight
 3. you know what? I am going to reduce the exactitude of the test, and test for equality of unit string in LciaDetail, and then just throw in a canonical lookup in the quantity_conversions machinery, and see if that does it.

then, the contexts specifically- e.g. (a) the fact that we don't want to be creating contexts all willy-nilly in the master Lcia engine, (b) even not broken, the do_lcia routine requires dist=2 to find matches between uslci and traci, (c) find_matching_context should not modify local contexts- should just find them.



A lesser problem is in the way we are catching ConversionReferenceMismatch-- since it's a thrown exception, we lose the opportunity to return what was learned during the conversion, crucially exactly WHICH quantities were unable to be reconciled.  This is solved by introducing a wrapper, where we use the interior if we want to capture and return mismatches (i.e. in do_lcia) and we use the wrapper to implement the interface (raising the exception if no match is found)


Sat 2019-04-13 07:49:35 -0700

Let's summarize where we are with contexts, which is the LAST PIECE OF THIS PUZZLE. Reiterate: when we solve the contexts problem, LCIA should *work*.

The main thing for the canonical set of contexts is to be the domain of CLookups, which are the gateways to QR.  CLookups get interacted with in four places:
 - in _factors_for_flowable and _find_exact_cf (more on that later), to retrieve CFs (via _qlookup)
 - in add_characterization and import_cfs, to create or assign CFs (via _qassign)

SO, in order for the LCIA engine to work, we simply need to ensure that the contexts used in these interactions are canonical.

HERE the problem is that add_characterization creates contexts via add_compartments, whereas import_cfs obtains a context from find_matching_context.

SO: what we should do :
 0- rewrite find_matching_context to be a "best-fit" engine that does not modify the context manager, other than to apply shortcut hints when it does find affirmative matches
 1- abandon the multiply-used LciaEngine. Only Qdb uses LciaEngine, because we don't want the canonical set of contexts to be messed with on external archives
 1a- foregrounds also use the LciaEngine.
 2- override add_context to use find_matching_context in the lcia engine, substituting NullContext for any non-matching context.  This is an interim / proposed solution but I think it should work.  The only thing it compromises is the (as-yet-unachieved and not even well-motivated) use case of supporting robustly multi-context characterizations of intermediate flows.
 3- establish the configuration framework above
 3a- manually assign origins to contexts created.. somewhere
 3b- yield context.fullname (if it is defined) first

Then, for LCIA- we will ensure consistency in context lookup because:
 - import_cfs will apply a valid canonical context (or at worst NullContext) via find_matching_context, taking advantage of context hints in config
 - do_lcia will search for a valid canonical context by using find_matching_context as well, "" "" "" "" "" "" ""

What is not supported but could be in the future:
- reclassifying CFs stored under NullContext to be stored under a more suitable context, which could be done by an exhaustive search of _q_dict[qq][*][NullContext][*]
            ^               ^
	    fb              list of contexts (or just one if SCLookup)
- potential problems with non-static resources learning CFs that are not linked to LciaEngine (but these can be handled by [re-]importing CFs)
- reassigning context hints.

This would allow poorly-configured LCIA resources to be rescued, and since find_matching_context is used dynamically, 



Sat 2019-04-13 18:14:30 -0700

Working on the train, I accomplished 0-2 and started 3, though that is obviously a big, open-ended project of indeterminate length.  The real thing I need it to do right now is to identify context hints.  But then I got distracted by the flowables list which is still only a skeleton.

I can get a long way there by importing the ecoinvent flowables, which is easy enough but not easy enough to fit into 90 minutes of work sitting in Jason's living room.  What needs to get done is: figure out the reference quantity (of which there are about seven), generate a FlowInterface, and then add it to LciaDb and save it.

OK, then try for LCIA.


Mon 2019-04-15 00:16:58 -0700

LCIA is so-so close.  We are getting non-zero results, only after merging "ecospold quantity kg" with "mass" (after discovery via LciaResult.errors()). Weird issue with 'co2, in air' coming up as a cutoff rather than a context-terminated exchange, when it seems as though the context is present (?).  So we will debug that,.... tomorrow?

the repetitive declarations of 'air' -> 'to air' and 'water' -> 'to water' are irritating.  and they apply to basically every resource.


==========
Thu Apr 11 09:21:59 -0700 2019

OK we are so close, rolling on up to Promontory Point, but we are still a bit off.

After quite some rumination I think I have the following model in mind:

 - When using the catalog, we only want to deal with quantities that are local to the qdb.  This means we want to give back either:
   * quantities whose _qi is a local.qdb implementation
   * quantity refs whose _query is to local.qdb
   that will ensure that the LCIA Engine gets all the requests for information.

 - At the same time, the quantity refs from non-qdb sources (including non-local sources) are self contained because bejezzuz if I didn't pull that off then what has all this effort been for anyway?
   * the locally-stored refs have the capacity *themselves* to retrieve their own factors; do quantity relation; etc, but the user will never see them unless they access the resource directly
   * instead, the catalog query will masquerade them
   * we want to store those quantity refs IN the local qdb archive, so that basic operations work to find them.

 - THE WAY IT ALL WORKS
   * anytime we get a non-canonical quantity, we want to make a canonical version
     - CatalogQuery intercepts get_canonical to ask _tm first
       + first we try to tm.get canonical
       	 = if it's found (and for paranoia we can check to see if its query is local), we're good- send it off
	 = if it's not found, we need to add it
	   --> add authentic ref to qdb entity store
	       + if its external_ref is already known, then we are kinda screwed
	       + no, we'll use links as entity keys, as in foreground. this is getting complicated and buggy.
	   --> create a new "masquerade" CatalogRef.from_query(local.qdb) and install IT as the canonical quantity; make sure that the link and external ref lookup to the masqueraded 

     - CatalogQuery intercepts make_ref AFTER THE FACT and runs get_canonical on the ref
       	 = so again: the authentic quantity_ref is stored in the entity_store
	 = the masqueraded quantity_ref is the canonical quantity
	 = the masqueraded quantity_ref has a query that is linked to the lcia engine, not the authentic source
	 = get_canonical(authentic quantity_ref) => masqueraded quantity_ref
	   --> this implies a mod to LciaDb.add() because that is the point where the qty is added to the tm
       + add/merge it to lcia engine (and import cfs)
   * we want to ask local.qdb first, not last, in gen_interfaces


Thu 2019-04-11 11:16:56 -0700

Shit. Another 90 minutes spent and we are... maybe incremntally closer? Now we are in context hell so I need another 6 hours to think + fix...
off to other things.

Thu 2019-04-11 17:08:31 -0700

OK, here's where we're at.
We've successfully tested through a lot of the issues. We are now at the point where foreign quantities are automatically loaded into the LciaDb.  The problem that remains is PROTECTED contexts (i.e. 'air', 'water', 'soil' which are ambiguous with regard to direction).

Essentially because we agree with Edelen et al, we decided that contexts MUST be directional, and therefore we cannot brook ambiguous directional senses in context terms.  We are TOLERATING this for subcompartments like "urban air" because resource extraction from urban air doesn't make sense.. but we are also doing this with water, even though the ambiguity is real there as well.  We've written enough infrstructure that WHEN we do something like add a foreign context ['resources', 'water', 'ground-'] where 'ground-' is already recognized as an EMISSION, then the incoming context is named 'from water, ground-' where the direction is detected via 'resources'.

What we HAVEN'T done is deal with ['water', 'ground-'] or even ['water'] where the direction is not specified.

The NORMATIVE solution is to use the 'context_hint' configure interface (though that is half baked because BasicArchives don't currently support the configure interface) but that is also irritating because it means every resource needs to be configured with these hints.  Now maybe that is just the cost of doing business but right now (a) it is not well supported and (b) it seems like a lot of work going on into the future.

The problem is that I can't think of any other way to solve the problem that ALSO preserves the protected status of the ambiguous compartments.  The other problem is that it is messy to apply because, once the CFs are loaded, the synonyms are wrongly learned and the contexts are all wrongly sorted.

Why are we even DOING it this way? whyy don't we just have a giant graph db of all the CFs and build an E matrix dynamically?

that would lead to many many many problems that are distinct from the problems we are dealing with. Andd wouldn't solve THIS particular problem either.

So stop it with that.  PROBABLY the best thing to do is to get the configuration process working....

OF COURSE THERE IS STILL THE FACT that when we load nonstatic resources that use the lcia_engine as term manager, we don't go through import_cfs so we don't find_matching_context and so we don't use context hints and so we are totally fucked.  How do we even add those contexts? just in add_characterization I suppose-- so they may not even have their origins SET YET- they may just have been created.

So This is a big fucking mess, in other words.




==========
Tue Apr 09 10:05:06 -0700 2019

Forward with testing.. getting a missing exchange error in configure.set_reference() why? because non-reference flows have their context as termination.  What should we do?
I think the most expedient thing to do is also the best: simply squash the termination.  This means we need to remove and replace the exchange, since termination is part of its hash.

Wed 2019-04-10 10:17:52 -0700

LCIA is not working for complex reasons, and there are at least two major points of incoherence in the code:

 (1) get_canonical is not used/behaving as expected
 (2) context lookup is not well defined w/r/t the NullContext singleton. Alternative ideas are:
     x NullContext applies to every failed lookup (deprecated)
     - NullContext matches every context
     x NullContext matches no context (facially wrong: unit conversions are intended to be stored with NullContext)
     x NullContext signifies an error

Related observation: it is an error for any interface method to return None.  It should return something or raise an exception.  I'm looking at you, get_context()

OK, so here's the deal.  EntityStore.__getitem__ returns None if no entity is found (i.e. catches KeyError), but SynonymDict.__getitem__ raises KeyError
CompartmentManager returns NullEntry for nonspecific items
ContextManager also returns NullEntry for disregarded items
they all still raise KeyError if nothing is found.  This is still consistent with SynonymDict (since in the two exception cases the object *was* found) but inconsistent with archive
And that's fine.  In fact the structure of AbstractQuery is premised on that- which is why None leads to the fallback exception (should maybe be EntityNotFound for those cases)

The question is for the TermManager- whether we should raise a KeyError or return None.  The code seems to assume we return None- which makes sense because the context is meant to be "entity-like".
So let's preserve it, and use NullContext strictly for affirmative identifications of cases where no context (or all contexts) applies, and tentatively assume NullContext matches any context that has not encountered another match (assuming dist>=3)
Then get_context returns NullContext if tm[cx] is None, and client code can handle that.  Exchanges already drop NullContext on __init__ (resulting in a true cutoff)

NOW... on to get_canonical
THIS method should do the following:
 - given a quantity or reference to a quantity,
   = return the corresponding canonical quantity already known
   = if no corresponding canonical quantity is found, raise a KeyError
   - the CatalogQuery is a special case: if the quantity is not known,
     = create a new canonical quantity from the information given
     = must provide a way to merge quantities
       * the challenge here is to make the merge persistent- i.e. to automatically store merged entries as synonyms that will get reintroduced
       	 The preferred solution to that is to use the entity_store- i.e. to add synonyms to the canonical quantity entities that get serialized
	 But we have not tackled serialization at all yet, which carries challenges with qty refs--
	 except we don't need to. We can: on merge, update the canonical qty's synonyms property. but we haven't added any non-local qtys to the qdb entity store. Then when the qdb gets saved, only local qtys will get written, including synonyms from the merge.

OK, so that needs to be done:
 x write code to store synonyms on merge of QuantitySynonyms objects
 x write tests for that
 .. write tests for qdb serialization
 x write a client-facing method to merge catalog quantities
 0 is that an interface method?
 Let's take a break and percolate on this, then implement it later.

==========
Thu Apr 04 10:52:40 -0700 2019

We are almost done! But I want to fix the interface.

 - add_characterization requires an explicit origin or else it defaults to the origin of the query quantity
   proposed solution: use the characterize() method of the interface
   The problem is that most of these use cases don't already have interface instances.  So I think we just audit them and switch where appropriate.
   add_characterization() 14 uses
    - quantity implementation characterize() - here we actually want to use it
    - configure implementation - should probably use it here too
    x antelope v1 quantity impl
    - term_manager - keep
    - archive _add_chars() - go ahead and use it
    - providers: traci, ilcd_lcia, ilcd, olca, ecospold - they quantity is already local
    - ecoinvent_lcia - added origin

   For testing, though, we should go ahead and use the quantity interface

 - QRResult = QuantityRelation Result. quantity_relation() should return a QuantityRelation Result!

 - cf - characterization factor. cf() should return a factor (pure number)! so these are switched

 - audit positional argument sequences:
  Flow-specific:
    def profile(self, flow, **kwargs):

  Quantity-specific
    def get_canonical(self, quantity, **kwargs):
    def factors(self, quantity, flowable=None, context=None, **kwargs):
    def do_lcia(self, quantity, inventory, locale='GLO', **kwargs):

  Characterization:
    def      characterize(self, flowable, ref_quantity, query_quantity, value, context=None, location='GLO', **kwargs):
    def                cf(self, flow, quantity, ref_quantity=None, context=None, locale='GLO', strategy=None, **kwargs):
    def quantity_relation(self, flowable, ref_quantity, query_quantity, context, locale='GLO', **kwargs):

    looks like it's in order. The only defect is with cf() because it expects a flow instead of a flowable, so ref_quantity is a kwarg and not an arg.

done. Thu 2019-04-04 11:51:36 -0700



==========
Wed Mar 13 17:07:12 -0700 2019

We are doing terribly. But we are close!

Auditing quantity implementation=-- what term_manager methods do we use?

 * get_canonical()
 * factors_for_quantity() [implements factors()]
 * add_characterization() [implements characterize()]
 * factors_for_flowable() [implements quantity_conversions]
 * __getitem__ [retrieves canonical context]

seems good.
Let's do ExchangeValue.__new__

The situation here is:

 * Exchange has 4 parts: parent, flow[able], direction (wrt parent), optional termination
 * termination = None means exchange is a CUTOFF
   = REFERENCE exchanges are the allocatable subset of CUTOFF exchanges
 * termination = Context with Context.elementary = True means exchange is ELEMENTARY
 * termination = Context with Context.elementary = False means exchange is a CUTOFF
 * termination = str means exchange is INTERMEDIATE
   = implication is that the termination must lookup as a valid external_ref in the local archive
     - if you want to terminate to something outside the local archive, use a fragment

Exchanges are created ALL OVER the code.  (17 usages in import statements)

So:
 (a) we need to change the invocation in many places and
 (b) we need to validate the instantiation.

Let's list all the usages:

antelope_background.background.implementation:
 (118) foreground() - yields ExchangeValues constructed from ExchDef() which come from TermRef()
       (should yield strictly intermediate exchanges, except for reference)
*(122) _direct_exchanges() - yields EVs
       	+ from _generate_exchange_defs() in the case of dependencies() or ad()
	+ from _generate_em_defs() in the case of emissions() or bf() or lci()
	= PROBLEM! the FlatBackground class has no archive and cannot access Contexts
	  - this means we need to do it in the bg implementation
	  - easy enoughh- just add a kwarg to _direct_exchhanges() that specifies whether to retrieve a context from tm prior to creating the ExchangeValue

antelope_background.engine.background_manager: (OldBackgroundManager)
 12 uses; obsolete so don't bother with this-- should be deleted from ContextRefactor

antelope_catalog.providers.ecospold2.ecospold2:
 (522) retrieve_lcia_scores(): used to create reference exchange; no changes needed

antelope_catalog.providers.v1_client.inventory:
*(72) _add_lcia_detail(): used to provide the exchange argument to LciaResult.add_score()
      - context should be supplied for completeness, but not required for functionality at this time

antelope_reports.tables.allocation:
 (87) _add_alloc_refs(): used to create a reference exchange for table output; no changes needed

lcatools.lcia_results:
*(412) LciaResult.from_cfs():
       - context should be supplied for completeness (grab from CF), not reqd. at this time
0(568) flatten():
       - context should be supplied for completeness (cannot grab), not reqd. at this time
0(586) flatten():
       - context should be supplied for completeness (cannot grab), not reqd. at this time
     
lcatools.terminations:
?(211) to_exchange():  ## is this method even used? It seems broken

*(389) _unobserved_exchanges(): used to generate exchanges for characterization of fg emissions
       - definitely needs fixed.  term_node should BE context in this case.
       ** this leads us to a FlowTermination refactor-- put on stack

lcatools.entities.fragments:
0(1012) inventory():
	easy fix (pending FlowTermination refactor)- just provide term.term_node as termination
	     (actually: need term.term_node.external_ref for non-fg-emissions)
	(actually: nothing to fix, as exchanges in inventory() are all cutoffs)

 (1077) cutoffs():
 	no change needed- they're cutoffs so termination should be None

lcatools.entities.processes:
x(353) inventory():       ** need to refactor ExchangeValue.from_allocated()
x(359) inventory():       ** need to refactor ExchangeValue.from_allocated()

*(573) add_exchange(): fix upstream
*(577) add_exchange(): fix upstream
*(581) add_exchange(): fix upstream
       ** need to fix all invocations of add_exchange()

11 upstream invocations of add_exchange:
   : 3 in process from json (!!! do we want to be back-compatible?)
   : 1 in olca JSON-LD
   : 2 in ecospold2
   : 1 in ilcd
   : 1 in ecoinvent spreadsheet (only ref- drop)
   : 1 in ecospold1
   : 2 in tests

Tasks on the Stack:
 X background _direct_exchanges()
 x LciaResult refactor: audit use of QRResult
 X v1_client.inventory _add_lcia_detail()
 0 LciaResult.from_cfs()
 x FlowTermination refactor:
    - top-to-bottom review
    - __init__ type checking
    - __init__ invocation checking
    - _unobserved_exchanges()
    - use of is_fg; add is_context
    - serialization: context serializes as 'context' not as {'origin':, 'externalId':}
    - deserialization: symmetric to above; try for bg compatibility
    - __str__, other diagnostics
 0 fragments.inventory()
 ** add_exchange() upstream

That's not half bad, actually.

and then remains:
 - just the CatalogQuery to hijack get_canonical
 - and rewrite the interfaces. let's do that now
I think we could get to the testing stage in 8 h work.


Fri 2019-03-15 13:48:10 -0700

HOLD ON for a fucking second.

HOW EXACTLY is LCIA supposed to work in the new order?
In the old order, we always used do_lcia() as a QuantityRef method, which fell back to the query implementation of do_lcia, which always felt like a hack.

In the new order, do_lcia is properly implemented in the Quantity Implementation- which returns it to the normal _perform_query() mechanism I THINK.... no need for a BasicQuery overriding implementation. 

Fri 2019-03-15 15:05:27 -0700
OK OK this is all good.

Remaining tasks:
 ** add_exchange() upstream
 - CatalogQuery.get_canonical()
 - implement the index interface
 - BIG FAT TESTING


==========
Fri Feb 15 12:54:22 -0800 2019

Where are we at?

OBJECTIVE: COMPLETE CONTEXT REFACTOR BY 1 March 2019

What does this mean?

 - Qdb, old Synlist, old CompartmentManager are GONE
 - Exchange.termination returns a CONTEXT, a string, or None
 x Archives have a TermManager which maps strings to objects, many-to-one.  Flowables map to strings, which are the canonical names of flowables; contexts map to Context objects
 x Flows can have a context or not-- archives derived from traditional data sources will work the same; but the term manager will be able to easily spit out flowables
 - 'Compartment' loses all special meaning except in instantiation
 - Characterization Factors are serialized separately from flows, though they can still be deserialized the old-fashioned way
 - Interfaces rewritten to include flowables and contexts, along with flows, in index

Mon 2019-02-18 15:26:06 -0800

Current usage of Term Manager // Quantity Interface

 Quantity Interface provides:
  - synonyms (obsolete)
  - flowables (to index)
  - compartments (to index.contexts)

  - get_canonical(quantity):
  - profile(flow): list of cfs for a given flow
  - characterize(flowable, ref_quantity, query_quantity, value, context=None, location='GLO')
  - factors(quantity, flowable=None, compartment=None)
  - cf(flow, quantity, ...) - returns the best cf
  - quantity_relation - returns the value of the best cf
  - do_lcia(quantity, inventory, ...) - iterates over inventory

 Term Manager provides:
  - __getitem__(context)
  - add_flow(flow)
  - add_characterization(...) implements characterize()
  - get_canonical()
  - qlookup() -> returns the flowable-to-factor lookup
  - factors_for_flowable() -> used to implement everything
  - factors_for_quantity() -> wraps f_f_f, implements factors()
  - get_flowable() -> for index
  - flowables() -> for index
  - de/serialization -> for ops

They are HIGHLY overlapping. The question is: is there a normative / design decision that distinguishes the Term Manager from the Quantity Interface? from the Quantity entity

Because remember we have this draggy situation where the quantity entity has to be given an interface- but that's not so bad- that just wraps up the term manager

and YES there is a normative / design decision: the term manager contains all the functionality that gets subclassed by the LciaEngine to work across data sources! boom end of story. stop with the endless introspection and move forward already!


==========
<<<<<<< Updated upstream
Thu Jan 11 10:26:15 -0800 2018
=======
Thu Aug 30 12:17:56 -0700 2018

I think today is the day for me to start the LciaResult remodel, as that will dictate how the new exchange world order is supposed to work.

Mon 2018-09-03 15:51:51 -0700



>>>>>>> Stashed changes

Since last September, we have considerably reworked [simplified] the interfaces system, but we are NOT DONE YET.

The following two major changes need to be made, both of which strongly affect LCIA:

 (1) 'flow' as a base entity needs to be abandoned in favor of 'flowable'-- reduce by 10x the number of entities in the db-- and 'context' needs to be added as a new entity.  Flow['Compartment'] is no longer A Thing; instead, an exchange terminates in a context:
 process-flowable-direction-context for elementary flows;
 process-flowable-direction-process for terminated intermediate flows;
 process-flowable-direction-None for cutoff flows (and reference flows)

This vastly simplifies the QuantityInterface implementation.

Moreover-- we have been talking about abandoning Qdb but I think the thing to do is retain Qdb-- and YES, give every antelope container its own private Qdb that it POPULATES by querying a public Qdb-- and have the DetailedLciaResult LOOKUP the factor in the Qdb when the exchange is specified.

Well, maybe that's a bridge too far. But it would be kind of neat if LciaResults were spun out by LciaEngines.

I wonder- let's enumerate all the places LciaResult()s are created, and see if a Qdb is accessible to (m)any of them:

<<<<<<< Updated upstream
* in LciaResult:
+  - add() 
+  - aggregate()
+  - flatten()
* in LciaResults:
  - __getitem__ [for null]
  - apply_weighting()
* in fragment_flows:
  - frag_flow_lcia() --> replaces traversal_to_lcia(); should be part of LciaEngine?
* in FlowTermination:
  - compute_unit_score [for null]
  - _deserialize_score_cache
* in LcProcess:
  - lcia()
* in EcospoldV2Archive:
  - retrieve_lcia_scores()
* in Qdb:
  - do_lcia()
* in AntelopeV1Client:
  - fragment_lcia()
  - lcia()
  
=======
 - test term manager but it's basically working
 - quantity relation is now implemented by the quantity
   = qlookup maps flowable to clookup
   = quantity clookup should be strict- errors flagged when a duplicate cf is added
 - move do_lcia into quantity interface
   + do_lcia is the only place that creates LciaResults
   + DetailedLciaResult changes to have the following components:
     - contextualized exchange or exchange ref
       	 equivalent to { node ref, flowable term, direction, context, exch val }
       = factor.value
       = location='GLO'
   + input is iterable of exchanges. algorithm is to:
     = lookup flowable in [quantity's qdict or query's qlookup]
     = further lookup context in traversing clookup
     = generate an lcia detailed result from exchange by associating a quantity relation result
     = lcia result has 4 sets:
       * cutoffs, which have null or non-elementary terminations
       * Lcia Scores, which have nonzero results
       * Lcia Zeros, which have zero or NoFactorsFound lookups
       * Fail, which reports exchanges that either had convert fails or flow / reference qty unknown
 - lcia engine is reimagined -> qdb will be ditched and replaced by current lcia engine
   = it's still a basic archive subclass, which reimplements the quantity interface
   = has its own quantity dict which maps quantity term to qlookup owned by the archive instead
   = that qlookup maps flowable to a SClookup
   = SClookup allows multiple cfs for the same flowable/quantity pair and resolves them at query time {i.e. as currently implemented}
 - all this can then be easily de/serialized for http
 - then we need to generate the reference context + flowable sets
 - then qdb is obsolete, it comes out / lcia engine renamed to qdb
 - then we need to reimplement the flowable / context / synonym in the index interface
 => and then we pop back to antelope v2
>>>>>>> Stashed changes

X in traversal_to_lcia() ==> moved to fragment_flows; unused

OK... we'll look that over a bit later and see if we can shrink that down.  But remember: in cases where the quantity arg is a catalog ref, the Qdb is available via the catalog.

Thu 2018-01-11 13:14:50 -0800

Thinking about this further.... giving the antelope container a Qdb causes problems as well: does it provide a quantity interface? I guess it does- to validate that its factors are the same as a reference.

The whole function of the Qdb is to abstract flow and container descriptors into "flowable" and "context" objects with synonyms.  If we give up the Qdb then we have to re-implement that functionality.

Instead, when we receive a quantity spec- we check to see if it's in our local set of lcia methods- and if not, we retrieve it from our reference Qdb- over the web via the antelope 2.0 interface.  So an antelope client is required to implement the antelope server? that seems dangerous.

They will be different subclasses of LciaEngine-- one for static archives and one for catalogs.  That's the part for me to work on right now.  

The only difference is in load_lcia_factors(). The Static Archive version implements load_lcia_factors(qid) by querying a stored remote Qdb resource.  The Catalog version works as currently written.

Mon 2018-09-03 16:49:44 -0700

FYI, quantity NEEDS context manager because, when we add_characterization, we then ask the quantity to register it with the cm.  So either the flow or the quantity (but logically, the quantity) needs a link back to the cm.




DEPRECATED
==========----------------------------------------
Mon Jul 30 14:19:41 -0700 2018

Context Manager methods:

 - add_context(string)
   = return string if successful

 - _create_flowable(string)
   = return string if successful

 - add flow-context linkage(flow with 'Compartment' or flowable, context, uuid)

 - add_synonym(existing_term, *new_terms)
   = raise if existing_term doesn't exist, or if any of new_terms do exist

 - getitem(term)
   = return None if not present
   = return uuid for entity if present

 - list contexts

 - list flowables

 - list contexts for flowable


Expectations:
 - BasicArchive stores contexts, flow(able)s, and quantities by uuid or otherwise valid entity key

 - context manager interceps requests for non-entities incl:
   * string names and synonyms for contexts
   * string names and synonyms for flowables
   * uuids that correspond to flowable-context pairs
   = and returns the uuids for the appropriate entities (context, flowable)

 - given a flowable, context manager should know all contexts in which it has been observed/reported
   * this is generally limited to elementary flows and only for classical archives that use the old flow definition;;;;;;;;;
   * terminated intermediate flows and exchanges defined with elementary terminations to flowables will not be known to context manager
   * however, archives that contain characterization data will be known

 - quantitative characterization information is unknown to context manager unless it is dependent on a flow-context pairing, in which case the existence of the characterization will be implicit but the value will not be known


==========----------------------------------------

Characterizations:

Now a characterization requires a flowable, a quantity, and an optional context.  It is still otherwise identical, except the natural direction is taken from the context instead of stored locally.


==========----------------------------------------

Qdb extension:
 - inherits from basic archive

 - pre-populates context manager with comprehensive list of flows and contexts
   * since this is expected to be moderately costly, it should only be done once per catalog (i.e. in the Qdb and not in the archive-generic context manager)

 - also adds a synonym list for quantities
----------
==========
----------

BELOW IS OUT OF DATE

==========
Tue Sep 19 16:42:04 -0700 2017

Complete mess right about now.

Here's the situation:

 - LcCatalog implements lcia() but this should be done by the catalog ref, in the inventory interface, for either process or fragment.
 - ForegroundCatalog implements fragment_lcia() but this should be done by the catalog_ref, in the inventory interface, with observed=True being hardcoded (cached vs observed values are only used under the hood)
 - Qdb implements do_lcia() but this should be done by the quantity catalog ref.  It uses Qdb.convert() but this should, again, be provided by the quantity catalog ref as quantity_relation()
 - CatalogRef should be subclassed. It should instantiate the subclass upon lookup- basically as soon as it knows the entity_type of the reference.
 - Qdb.get_canonical_quantity() appears to be totally useless, its usage pattern is deeply confused, and anyway it is functionally redundant to Qdb.get_quantity()

Other issues:
 - FlowTermination currently logs subfragments, but these should be part of the FragmentFlow, because they are determined at traversal time, and to store them in the entity just begs for synchronicity problems.

Given all these, there remains more or less NO core utility to ForegroundCatalog AT ALL.

OK.  So it looks like we are shifting more stuff to the implementations- that is good- but the quantity one needs some thought.

First: compare and contrast the signature for quantity_relation() with the signature for Qdb.convert()--

Before we even get into that, keep in mind that Qdb.convert() is sprawling and occupies a considerable amount of Qdb.  The whole POINT of Qdb is convert().  and it CANNOT be localized to the quantity because it requires knowledge of other quantities. it REQUIRES Qdb.

A Quantity doesn't implement the QuantityInterface-- a provider implements the interface.  A quantity merely accesses it.  I think I am getting [more] confused.
Look- ONLY the Qdb fully implements the quantity interface.  The point of the catalog ref is to anchor the query entity to the provider.

But let's go ahead with the comparison:

self is anything that implements the  QuantityInterface:
def quantity_relation(self, ref_quantity, flowable, compartment, query_quantity, locale='GLO', **kwargs): 

self is Qdb:
def convert(self, flow=None, flowable=None, compartment=None, reference=None, query=None, query_q_ind=None, locale='GLO',
                quell_biogenic_co2=None):

They are identical, except that convert is flexible between a flow and [flowable, compartment, reference] and between query and query_q_ind, and convert accommodates quell_biogenic_co2

The point is, ONLY the Qdb is supposed to be able to implement the quantity_relation.  That was the whole reason for creating the Qdb.  The quantity merely provides a convenient way to access it-- but really that should be from the flow and not the quantity.  Or rather it COULD be from the flow just as easily as from the quantity.

ok.

routing, then:
the user, through query, identifies a flow[able + compartment] with a known reference quantity and wishes to know its characterization w.r.t. a given query quantity.
IF a proper flow entity is primary, the query would look like:
origin/flow-ref/cf/q-ref/locale -- where q-ref is a shorthand known to the catalog, and 'cf' is literal.  The implicit origin is self. 

The catalog needs to lookup the query quantity-- there has to be some way to get from the q-ref to a data source:
 * if the Qdb knows the quantity, then the q-ref should bring up an entity, which the catalog can use to track down a resource providing the quantity interface for the entity's origin.  So for that to work, the quantity would need to be present in the Qdb's quantity SynList.  That's fine- the SynList is maintainable.
 * if the Qdb does not know the quantity, then it can't lookup the cf.

On the other hand, maybe the user specifies the query quantity as primary: 

qdb/origin/qty-ref/convert/ref-qty/flowable/compartment/locale

that's an awfully complicated query statement.

Tue 2017-09-19 17:14:19 -0700
whatever whatever.

For now let's just leave do_lcia() as part of the Qdb, and only refactor how it gets accessed-- namely, by the implementation of the InventoryInterface for processes and flows, and internally by the BackgroundInterface for bg_lcia (as already done).

BasicImplementation.characterize() and its counterpart in BackgroundImplementation.bg_lcia(): these exist in order to use a specified, non-native Qdb to perform LCIA of a local inventory.  It doesn't make any sense for bg_lcia() to use this-- bg_lcia will need to know the CFs locally.  The thing to do is to add them to the local Qdb, not to specify a remote source on-the-fly.

To mix and match sources requires a runtime environment anyway-- the user can add a new resource to her resolver that will allow the quantity's factors to be retrieved and loaded locally.
The downside of that is if there is a collision in the quantity SynList.  Presently, the external_ref, link, ['Name'], and __str__ are used-- so if any of those collide-- in particular the external_ref and ['Name'] preclude the knowledge of different versions of the same quantity.  It may be that the q-SynList should only track links.

I could work around that simply by setting merge=False in Qdb.add_new_quantity() on the call to add_set()-- then the name and external ref will be bound to the first entry, but the alternate cfs will still be accessible using the full link.

This means that _get_q_ind will need to find fully-specified links first.  That just means that _q_terms should be sequenced differently.
Done.

ok.

oy oy oy.

Tue 2017-09-19 17:27:57 -0700
So-- 3 minutes to wrap this up:
 - RESTful implementation of the quantity relation is still a bit sketchy
 - but local implementation should still be fine.
 - steps required:
   X get rid of get_canonical_quantity
   X move LcCatalog.lcia() into InventoryInterface-- scratch that-- no, unscratch it
   X move ForegroundCatalog.fragment_lcia() into InventoryInterface
   X move aggregate_subfragments() into FragmentFlow
   * then work on subclassing CatalogRef.

Tue 2017-09-19 17:31:17 -0700


==========
Tue Sep 19 22:23:37 -0700 2017

Let's think this through a LITTLE bit more.

We can't move lcia() into the InventoryInterface because the InventoryImplementation doesn't have access to the catalog's (private) Qdb.  BUT- both Quantity and Background already require qdbs; in both cases they just use the catalog's own.  Why not simply make the qdb publicly accessible?

Tue 2017-09-19 23:15:02 -0700

ok... checked that off... tomorrow is the testing.

==========
Wed Sep 20 15:12:04 -0700 2017

Today, that is.

Let's look into subclassing CatalogRef.
On the one hand, this doesn't seem like it would work because we want to be able to create a catalog ref without knowing what kind of entity it corresponds to.  Once we create it, we can't exactly morph it into a subclass.

One option is to have CatalogRef create subclasses through the use of class methods.  This seems trick because we can just replace invocations of CatalogRef() with CatalogRef.new().  This seems like it would be prone to circular dependencies-- we would have to have all the subclasses in the same file because the constructors would need to be able to see each other.  That is basically exchanging one antipattern (having all the tricks in one class) with a slightly less obviously broken antipattern (having all the tricks in one file).  Plus it's contrived.

Another option is to have the catalog generate the ref-- but that is undesirable because the whole genius OF the CatalogRef was its lack of dependency (currently, catalog_ref.py imports literally nothing)

So what's the problem with the status quo, exactly?  We have to police all the methods. Every method needs to check for entity_type compatibility before executing.  NEEDS TO is maybe too strong a term, but it certainly provides a courtesy to the user.

I mean, the function is not THAT long, and it grows slowly.

Let's audit:

lines 0-20: Exception classes
lines 21-26: Class definition + basic doc
lines 27-42: from_json(), accepting 'entity_type', 'origin' OR 'source', and 'externalId'
lines 43-90: __init__(), including 20 lines of doc
lines 91-95: _check_query() -- ERR_CHECK
lines 96-122: query access methods
lines 123-166: properties (including the somewhat concerning default_rx)


OK there are two different things going on, and these are the things that should be split into separate classes- and not even subclasses- totally separate classes.

First is the catalog lookup.  I specify an origin and an ID, and the catalog lookup gives me a floating reference that I can use for... well, nothing really.  All it can do is perform the lookup and give me a grounded reference that IS one entity type.

Looking over the code, there are some functions that are only useful if _query is None, and many functions that are only useful if _query is non-None.  And a few things that are ambiguous: like _d access.

I think I will create a new package called catalog_ref and give it:

A base class with origin, external_ref, and _d;
a set of entity refs that inherit the base class and provide entity-specific functionality, but require the query to be passed as an argument;
a catalog ref that inherits the base class, imports the entity classes, and provides lookup functionality and RETURNS one of the entity refs.
