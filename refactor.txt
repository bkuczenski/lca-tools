LciaResults:

 * need __add__ method for AggregateLciaScore and SummaryLciaResult
 * aggregate method should preserve content
 X need a "deep aggregation" that would combine components and generate fragment LCI - flatten()

Fragments use:
 X process-to-fragment !! (done??)
 == the unit of this is fg.terminate_child(term, flow, direction, new_term)
 then just: for x in inventory (opt. include/exclude cutoffs / elementary)
 this is just term.from_exchange
 but what I really want to do is auto-terminate. bg does that; fg does not. simple as that.
 index interface offers to terminate.- that's interactive

 == want to be able to compute cutoffs even if not adding them to frag
 -- but why not add just them to frag?

todo for reporting:
  - pretty-print frag.inventory (think Virent)
 - list cutoffs w/o magnitudes
 - results table
 
General Issues:
 X entities: @property external_ref
 X entities: set origin, external_ref at init
 X interfaces: need both source and ref. source is argument to Archive(); ref is entity.origin
   = does this weaken provenance?
   X archive handles physical access
   X catalog handles semantic reference
 - entities: merge requires equal origins (pending above)
 - lca-data-files; update with semantic origins
 - flows: factor, cf, convert need to be scenario-aware
   = characterizations need to be scenario-aware
 0 flow terminations: inbound_ev should not be cached; should be computed live at query
   WRONG - inbound_ev SHOULD be cached to enable offline use and reduce startup time. no need to query the same resource more than once.
   = but flow conversion is *already* computed at query time; ev is not parameterizable
 X refactor LcFragment-- make it an entity
   = it's already an entity; take out stuff that it doesn't need to own
   X! the big question being: can we avoid passing a child_flows lambda as an initialization parameter? (answer: YES!)
 X FlowTermination-- a top-level entry? I think so.
 - termination - flow conversions - move into LcFlow
 - exchanges: need tests
 - characterizations: need tests
 - terminations: need tests

 - BackgroundManager: need to slightly rework how it handles multi-output processes to enable graceful handling of unallocated foreground processes
   = need to assess whether it is possible to gracefully handle unallocated background processes, and what would be required
   = it already runs... what it does is cutoff completely. What we want it to do is:
     * first time through, drop in complete unallocated inventory, including other references
     * all subsequent times through: cutoff everything.
     * except subsequent times would not occur because the product flows would be detected.
   = I think it would be possible to simply assign each non-acc
 X BackgroundManager; need to split into the matrix-handling part and the interface-providing part

Lingering Catalog issues:
 X Qdb needs a config switch to handle "biogenic carbon"
 - further configuration for other special circumstances??
 - CLookups should progress from being sets of attributed CFs to being single canonical CFs
   = exceptions raised on add_cf instead of during conversion

 - either exchanges, or LciaResult objects, or CFs, need to screen out / correct for "wrong" directions (INVERTED)
 
Antelope refactor:
 - Fragments need to use an interface as well: only place they are accessed is from FlowTerminations
   This has far-reaching implications:
   = CatalogRefs need to have a base class
   = ProcessRef, QuantityRef, FragmentRef (FlowRefs should be discouraged)
   = QueryInterface needs a subclass
   = LcCatalog.query needs overloaded
   = FragmentRef implements the Antelope interface
 - Required properties of a FragmentRef:
   - is_background
   - traverse (returns a list of FFs)
   - newly created unit_inventory is problematic since it returns a tuple.
     (the cost of splitting it up would be to repeat the subfragment traversal-- but that seems to be cheap)
     (could cache it in the foreground)
   - origin, external_ref, entity_type == 'fragment'
   - as process in Exchange:
     = __str__
     = flow, direction (for printing reference only, but important for completeness)
     = reference_entity
   - flow
   - direction
   - term ! (for detecting termination type.. currently broken)

 - Antelope methods used by the js FrontEnd:
   = dissipation-related (pending reform in dissipation.txt):
    : compositionFlows
    : processes/:processID/dissipation --> always return null [[ replace with dissipation fragments ]]
   = fragment-related:
    : fragments
    : fragments/:fragmentID
    : fragments/:fragmentID/fragmentstages
    : scenariogroups/:scenarioGroupID  [ used to demonstrate authentication status ]
    : scenarios
    : scenarios/:scenarioID
    : scenarios/:scenarioID/params
    : scenarios/:scenarioID/params/:paramID
    : [scenarios/:scenarioID/]fragments/:fragmentID/flows
    : [scenarios/:scenarioID/]fragments/:fragmentID/flowproperties
    : [scenarios/:scenarioID/]fragments/:fragmentID/fragmentflows
    : [scenarios/:scenarioID/]fragments/:fragmentID/lciaresults
    : [scenarios/:scenarioID/]fragments/:fragmentID/lciamethods/:lciaMethodID/lciaresults
   = FG catalog-related:
    : flowtypes/:flowTypeID/flows
    : flowtypes/:flowTypeID/processes  [ used for selecting processes with elementary flows ]
    : flows
    : flows/:flowID
    : flows/:flowID/flowpropertymagnitudes
    : impactcategories
    : impactcategories/:impactCategoryId/lciamethods
    : lciamethods
    : lciamethods/:lciaMethodID
    : lciamethods/:lciaMethodID/flows
    : lciamethods/:lciaMethodID/lciafactors
    : processes
    : processes/:processID
    : processes/:processID/comment
    : processes/:processID/flowproperties
    : processes/:processID/processflows
    : [scenarios/:scenarioID/]processes/:processID/lciaresults
    : [scenarios/:scenarioID/]processes/:processID/lciamethods/:lciaMethodID/lciaresults
 

==========
Tue Aug 01 13:19:40 -0700 2017

OK, what am I doing now?

The Catalog (and especially the ForegroundCatalog) are complete messes.

go to catalog.txt for notes on this.

Wed 2017-08-02 16:16:19 -0700

More open questions:
 * What's with upstreaming? Do we still want to be able to do that? It seems like kind of a lot of trouble.

The idea of upstreaming is that if a given entity already exists, we can reference it rather than creating a new one. This is mainly to address the situation where flows get characterized in one archive and referred to in another.

ON THE ONE HAND, this is useful and even vital for stand-alone LCIA computations inside of archives.

ON THE OTHER HAND, it causes a lot of problems. First- the flows have to match by UUID, but since flows aren't necessarily known by uuid (at least in ecoinvent from the spreadsheets, they are known by name + compartment) that introduces the need for an upstream dictionary.

Second, it means that when archives are deserialized, their upstream references need to be populated.

Third, it means that when archives are created, the upstream archives need to already be in place, which means this process needs to be very tightly managed. which is not desirable.

Fourth- the Qdb's whole reason for being was to eliminate the requirements that flows be individually characterized, because they can simply consult the Qdb when LCIA results are needed.  So why am I even bothering?

Now, the upstreaming feature is starting to seem more useful to explicitly take advantage of the Qdb, i.e. for quantities instead of for flows.  If we can put a Qdb upstream of an archive, then we no longer need the archive to possess all the core quantities (and in fact, it gives us a way to resolve compartment queries too! but only if we can count on there being a Qdb at the top of the stream)

Foregrounds, too, need to be able to be upstream of one another... or do they?


Related issue:

 * Do we want the ability to override external refs to be a general feature of all entities in all LcArchives, or only a feature of fragments and thereby only in Foreground archives?

==========
Thu May 25 14:49:58 -0700 2017

I need to work out the argument types.  At this point I am passing a mishmash of entities, catalog refs, and strings among all the various layers of the catalog interface, and it's super messy.

What's the story here, anyway?

 1- The original idea was to use CatalogRefs for everything, and provide them with the functionality necessary to acquire data from their data sources via the catalog interface.  This in particular was how term nodes were supposed to obtain inventory + lcia results during fragment traversal and fragment LCIA.

 2- There was also an idea to make everything REST-ful and text based, where we could submit a query via an HTML request and get back correct information.
  * a major monkey wrench to this is that external references (in ILCD) contain slashes, which complicates token extraction from the request.
  * Anyway, this does not necessarily apply to the use of CatalogRefs or the QueryInterface, since those will ultimately be accessed via wrappers if an HTTP layer is added.

 3- Then, complicating matters is the requirement that flow entities somehow maintain their characterization information, which they get from the Qdb, and which led to the decision that QueryInterface functions would return catalog refs for processes + quantities, but actual entities for flows.

Now we are faced with the actual application, where we have a node in a fragment, which is a background process, and we want to get LCIA of it using a quantity catalog ref.  Presently, the qdb is expecting to get a synonym string, which it can then lookup in its Synlist for quantities.  But we are passing quantity CatalogRefs because we also want the Qdb to be able to load factors BEFORE answering the query.

Let's review the various layers again:

QueryInterface: Directly from the code, the documentation says "The arguments to a query should always be text strings, not entities.  When in doubt, use the external_ref."

That's easy enough.  That is consistent with how the Interface Providers are written.  But I've already relaxed things, expecting that catalog refs (or even literal flow entities) be passed as ref_flow arguments when asking for process references.  Well, not exactly- those things are happening in the CatalogRef class itself, not via the query interface.

The only case where we really do need to make an exception is when the Qdb is involved, because the Qdb may need to load quantity factors.  In that case, we should really require that quantities, when supplied as arguments, strictly be either entities or catalog refs.  but really catalog refs, because entities don't have the capacity to invoke a query interface.  We could construct a ref from an entity from *within* the catalog.

What are all the instances where a quantity is passed as an argument?

 * bg_lcia

that may be it.

The catalog has to be the thing to add the CFs, since the Qdb doesn't have the capability to lookup factors (though if it had a catalog ref, it could just ask the ref to do it.)

BUT last night I made the late-night, pot-addled decision to continue to use quantity uuid as the key in flow termination Score Caches-- why? because the LciaResults dict gives me the ability to specify a desired quantity only by specifying a unique string.startswith, and if I were using external refs, I would need to specify 'lciaresults/37' instead of just '37'.  Not really a good reason to make an architectural decision.

The qdb currently accepts quantities all kinds of different ways:

Expects a string / synonym:

 - get_quantity(synonym)
 - flowables
 - factors

Expects an entity or ref:

 - _q_terms
 - add_new_quantity
 - do_lcia - agnostic; but if str, then canonical entity must be ref in order to auto-load CFs

Agnostic:

 - _get_q_ind -> converts everything to index
 - is_loaded
 - get_canonical_quantity
 - convert: uses _get_q_ind for both reference and query




==========
Thu May 18 11:41:38 -0700 2017

Background overview:

 - QueryInterface establishes the background interface as providing the 'partial ordering' results:
   * enumerated foreground, background, and exterior flows
   * exterior divided into cutoff and emissions by compartment manager
   * foreground - linked list of terminated exchanges- basically a fragment factory!
   * ad, bf - the foreground-aggregated versions- lists of exchanges
   * lci - list of exchanges
   * lcia - LciaResult

 - Background interface implements these for a given archive
   * if the archive is static, then background engine can construct and invert A matrix
   * otherwise, the archive is assumed to be already aggregated: "foreground as background"
     = interface access is provided by a proxy
   * background interface accepts references as arguments - retrieve_or_fetch_entity
   * background manager and proxy accept entities as arguments
   * background manager and proxy produce exchanges
   * background manager handles characterization internally
   * proxy does not do characterization- interface does it as-foreground

How about the Qdb?

 * Qdb starts up just fine with a limited set of reference quantities and a narrow set of flowables (TRACI 2 xls)
 * to add a set of CFs for an LCIA method requires:
   - ensure all the flowables exist; create new flowables if necessary
   

==========
Wed May 17 10:39:40 -0700 2017

Things are moving fast and slowly.  Need to re-think the catalog interface information flow:

Originally, catalog refs were meant to allow client code to retrieve the objects at will. that's why they included a cached entity.  But in the new way of doing things, the catalog goes-between the client code and the origin archive, and the origin has control over what information is provided.  In that case, the catalog ref should NOT cache the entity, and in fact the actual entity should almost never be returned to the client code.

So what should be returned? a catalog ref.  Should ALL interface methods that return entities actually return catalog refs? I think so.

New plan: fetch() only works by directly accessing the catalog.  The interfaces strictly return catalog refs, so that subsequent queries to those refs still go through the interfaces.  The catalog refs will strictly cache trimmed entities, because the quantitative data should be accessed through the query methods.

Need to figure out how this works w.r.t. the qdb.  I think the qdb should store its own characterized flows-- it is an LcArchive after all-- and the external_refs for those flows should be the flows' links (origin + ref).  The characterization data stays local in the catalog; the interface provides flows by reference anyway, so the way it works is: for foreground LCIA queries, the interface provides the inventory and the catalog consults the qdb for characterization.  for background LCIA queries, the interface provides LCIA results directly.

Wed 2017-05-24 23:04:19 -0700

Instead of this we soften things, and processes and quantities stay catalog refs, but flows are returned as entities. This way the flows accumulate characterizations over the instantiation of the archives.

==========
Mon May 01 00:44:54 -0700 2017

todo on background manager:
 - setup to use the ForegroundInterface instead of the raw archive
 - officially move termination into the archive
 - move all the client code into a BackgroundManager-- crib from background.py and foreground.py into background_manager.py in lca-tools
   Just look at the API spec:
   + foreground, background, emissions
   + LCI of productflow
   + ad-tilde of productflow
   + bf-tilde of productflow
   + lcia of productflow wrt qty

and if we look at ForegroundFragment, we see:
   + foreground of productflow
   + is_background productflow
   + make_foreground productflow
   and then:
   + background, foreground, emissions
   + lci of product flow
   + lcia in sparse-format

==========
Tue Apr 25 09:31:30 -0700 2017

Time to officially start with the catalog refactor.

The resolver is the core of it-- takes entity 'origins' or catalog 'refs' and translates them to data sources.  The data sources will have three different types that will provide different levels of functionality.

 - "Catalog" will provide a listing of entities.


==========
Thu Apr 20 12:51:35 -0700 2017

Doood, where are we even going with this??

The ForegroundFragment is the new point of reference because it includes a straightforward serialization that has been submitted for publication.  Software development going forward should use this as a basis:

 * Ability to serialize and deserialize fragments consistently is a performance benchmark
 * The equivalency of ForegroundFragments and collections of LcFragments is a performance benchmark.

What functionality does the ForegroundFragment require?

 * access to an inventory data provider (BackgroundManager)
   - 
 * access to a quantity database (FlowDB)


Not sure we accomplished much here.

Fri 2017-04-21 10:59:06 -0700

Let's think about scenarios a bit.

Of the original 10 parameter types in the .NET antelope, two types remain:

1 - fragment flow param => ev param
2 - discontinued
3 - discontinued
4 - flow property param => characterization param
5 - composition param => characterization param
6 - dissipation param => eliminated?  see discussion below
7 - discontinued
8 - process flow param => disallowed for background processes; so require Lcfragment and make it an ev param
9 - discontinued
10 - characterization param => .

ev params are computed during traversal; their result is encoded in the FragmentFlow stack.

a slick thing would be for LciaResults to automatically account for params by composition. The exchanges are already stored, and totals are already dynamically computed, so in principle that should not be a problem.

in practice-- LCIA results are made up of two different objects: DetailedLciaResults and SummaryLciaResults.

SummaryLciaResults are static node weights and unit scores.  They are not scenario-sensitive.  It would be very hard to make them scenario-sensitive.  unless we made a SummaryLciaResult simply a wrapper for an LciaResult. then it's dynamic computation all the way down.

We have an __add__ method for LciaResults.

Appealing.  but we need test cases in order to validate it.  add_summary_result is only called from two places: LciaResult.aggregate(), where the input is already an AggregateLciaScore.cumulative_result; and in FlowTermination.from_json, where the input is not expected to be dynamic.

Hold up- we also have a way of transferring duplicate DetailedLciaResults to a single SummaryLciaResult when their locations don't conflict.  But we could do that with a clever __add__ as well.

ok, it's 12:00- time to go to lunch.  But just the takeaway-- what this gives us is the ability to have DetailedLciaScores dynamically computed with respect to scenarios; what it would require is for ExchangeValues and Characterizations to accept scenario arguments and thus to store scenario-specific values. That is very complicated with allocation and with spatialization, because each would have to be replicated for each scenario. that could get pretty tricky. and it would all have to be serialized.

AND WE STILL have the problem where flow properties are supposed to affect traversal.

so it may yet not work.

and we didn't make any progress on the catalog interface. much less on AUOMA.




Dissipation Processes

dissipation processes may only dissipate 100% ???? this does not make sense
    Dissipation is a killer. choose one: consistent mass balance, 100% dissipation. we can't have it both ways.
    unless we start doing crazy shit like dynamic flow property computation.  I mean, that's not out of the question -- given the dissi ---> to dissipation.txt
    

==========
Mon Mar 27 13:16:32 -0700 2017

The Archive Interface:
 * keeps a collection of related entities
 * is anchored to a particular data source
 * can have an upstream archive
 * serializes and deserializes
 = gets and adds entities
 = keeps a uuid for every entity
 * provides a mapping from key to uuid, in the event that external keys are not UUIDs

the LcArchive:
 * specifically identifies entities as processes, flows, or quantities
 + needs to be extended to create a BackgroundManager as needed
 + need to standardize interface to answer certain queries. current half-assed interface:
   - flows, processes, quantities, lcia_methods
   - terminate - outmoded- generate processes that terminate an input exchange- BackgroundManager does this better
   - exchanges - list exchanges having the given flow, opt. direction- could be useful
   - fg_proxy, bg_proxy- not sure
   - fg_lookup, bg_lookup- not sure

the Foreground:
 * keeps a collection of fragments

The LcCatalog interface:
 * at its core is a RESOLVER which relates semantic references to data sources
 * also manages access to a flow db for explicit compartmentation + characterization on demand of LcArchive flows
 = CatalogRefs are an archive-ref/origin + external-ref/id. Catalog resolves them to data sources.
 = also contains one (or many?) foreground(s), which store LcFragments
 = loads + saves archives and handles nicknames for them
 

==========
Tue Mar 21 22:57:26 -0700 2017

Progress!

 1- the new concept for archives and particularly background archives seems sound, namely:
   * archives are read-only
   * processes already know how to do their own fg lcia, provided flows are characterized
   * a background manager:
     - operates on an archive
     - provides / is required to compute lci

 2- the flow/qty db needs to be completely rethought / reworked
   * a query consists of a flowable, REFERENCE UNIT, compartment, GEOGRAPHY and query unit.
   * all 5 of these components are required to compute the conversion factor
   * should return a float, not a CF. why encumber the client with CF baggage?

 3- catalog refactor will be total.
   * this is a drag as it could jeopardize the AUOMA work
   * still, the concept of a catalog ref being made exclusively of entity.origin + entity.external_ref is incredibly appealing
     - entity.uuid being a suitable substitute for entity.external_ref
   * but more to the point, LcFragments as being constructed FROM ForegroundFragments is incredibly appealing.
     - right now, only background managers can generate foreground fragments-- perhaps every archive should have a background manager operating by default.

 4- LCIA- seems to be correct, up to about 5%, which could easily be explained by quantity matching

Optimizations I want to make at my earliest convenience:
 * the old exchange.is_reference() / improve process reference_entity membership
 * background should go ahead and construct ad and bf, and extract columns- will slash the time cost of make_foreground (on Ecoinvent: 2-3 msec vs 40-70 msec). Since the ecoinvent breakdown for lci is approx: 40-70 msec for make_foreground; 200 msec for iteration; 100 msec for exchanges, getting rid of make_foreground is huge
 * E matrix- option to report all characterized flows
 * Af, Ad, Bf- option to report full [truncate 0-rows] vs sparse
 ( sparse report should put everything in a single data column? make it extra-sparse? nah; clearer if you can see what's being presented)
 * Cutoff flows need to be upgraded to the foreground-- this requires the application of the flowdb, since it is the only thing that knows how to tell intermediate from elementary flows.. however, once available it should be easy to sort _bg.emissions into cutoffs and elementary flows.
 * get pandas out of ForegroundFragment; get dependencies on pandas out of ForegroundTable

 * ArchiveInterface needs to log both source and ref.  origins of all these entities should be semantic references, rather than physical sources. That's going to require migration of all the archives.
   - or- could be done on load.  Load archive, get ref; when the archive is added to an LcCatalog, the catalog manages 


Thu 2017-03-23 10:35:56 -0700

LCIA investigation-- the LCI has always been right, so the error cannot be a matter of sign reversals on waste flows.  Instead, it must be in LCIA.  So just to confirm, I've chosen a lightweight foreground system; generated a publication with 10 different CML CC impacts; comparing against the reference results on the ecoinvent website.

(maybe I should compare against the logged LCIA results in the spold distribution? they must be the same...)

anyway-- the product flow is:
treatment of poultry manure, drying, pelleting [RoW]:==poultry manure, fresh [By-product classification: Recyclable]

loaded ecoinvent CFs into flow DB-- 92 excluded flows.

checked against CML- 35 excluded flows have CML characterizations

but matching those flows to flows in bg is what the flow db is for--- and so far that is hard to do.

Thu 2017-03-23 15:13:38 -0700

but of course it comes down to Ecoinvent's omission of biogenic CO2.

acidification is dead on. let's try tox ... [CML] tox is spot-on (5 methods checked)
of course, there's the sign reversal-- but why is that there? that is there because our data are already normalized to a unit output AS PER the demands of the iteration

anyway, LCIA seems to be solved.




==========
Mon Mar 20 11:27:04 -0700 2017

On the one hand, the objective for right now is very simple: we want to take this background manager we've made, use it to generate a foreground fragment, and then use the fragment to generate a publication.  To do this properly, we want to use the same publication mechanism to publish LcFragment-based foregrounds.  The problem is, the publication depends on the background manager all the way back, in order to compute background process LCI.

This is expected.

The problem is: what to do when background LCIA is not computed from background LCI? e.g. in the LcFragment case. We can't exactly cast a FragmentFlow stack to a BackgroundManager.  There has to be some other way to resolve the LCIA query.  We also can't make it self-contained because, at present, the ForegroundFragment contains the characterization vector.

So there you have it.  EITHER:
 * ForegroundFragment contains the characterization vector; background nodes supply LCI
 * ForegroundFragment contains the characterization vector and passes it to the background node on query- the problem here is that this is costly, since the c.v. is stored as a sparse matrix and not as an entity set
 * ForegroundFragment contains the foreground characterization vector, and background is responsible for developing its own characterization (in which case I need to implement this for BackgroundManager as-is)
 * ForegroundFragment loses characterization vector; only background managers do characterization. but this is counter to the spirit of separated concerns.

I think the cleanest approach is to require background to do its own LCIA. But HOW?

how is LCIA done right now: well, in lca-tools it's done by the foreground manager. background is required to provide LCI.

There's also the lingering anxiety about mashing up emissions vectors from different sources.  EITHER we have a strong foreground manager that figures out which is which, or we leave it up to the background managers to do it themselves (and supply a qdb for the purpose).

The foreground should DEFINITELY maintain its own CF data and its own list of emissions.  And it should map those CFs to background emissions on demand.  The FG -- catalog manager now -- should keep a list of each archive's emissions and map into them.

Or no.  The catalog manager should just have a flowdb on tap, and hand it over to the bg archives along with any request for LCIA.  The bg archives should simply characterize their flows and run ordinary process-owned LCIA.  And background LCIA can only be answered by a background manager, since it is the only class that builds and inverts a matrix.

So there we have it.  The problem with this is that it does not require fg and bg LCIA to be cut from the same CFs. But maybe that is a feature, not a bug, because different databases have e.g. different localities.  It does require that fg and bg LCIA be cut from the same FLOW DATABASE, which should be the subsequent source of inquiry because it can be independently managed.

So a workflow is starting to come together here:

 * a workspace includes a flow db with an accompanying flowables list and compartment manager, just as at present
 * a foreground manager IS a catalog, which keeps a dict of archives by ref and looks up references by origin
   - the foreground manager also holds on to the flow db
 * an archive comes with a background automatically, which is used for answering all lci queries.
   - The background can be used to spit out publications about the archive, such as foreground tables
   - LCIA data has to come externally.  It can be added to the foreground fragment, which is the natural thing
     to do, but as long as we have a background we may as well continue to explicitly use the LCI.
 * the foreground manager also keeps a set of fragments, which are very similar to the foreground components of
   background archives, except they vary with scenarios.
   - LcFragments in the foreground can be cast into a structure that is very similar to a ForegroundFragment, by
     using a traversal record (list of FragmentFlows; enhanced to include exchange value)
   - a separate mechanism is needed to publish this. Why make them the same when they are different?
   - this can also be used to seed an antelope implementation.
 * The foreground/background archive has to be useful to CREATE fragments.  We need to call them by different names though.

BUt not really- the point is that foreground fragments are created in the background archives.  Then we just take the product flows, which are already ordered, and make them into fragments. 


New plan. new plan. Don't refactor anything in background. Reimplement for fragment output when we get there.

the LCIA thing is still sticky though. 



==========
Sun Mar 12 22:38:10 -0700 2017

What do we want an LcMatrix to do?

More to the point, what do we want an LcCatalog to do?
1- this is the thing that keeps track of compartments
2- this is the thing that keeps track of [archive] refs
 2a- CatalogRef should be catalog (or None for floating ref), ref (i.e. LcArchive.ref), id (or key)
 2b- CatalogRef can be created w/o a catalog (floating) and be anchored to a catalog later

3- json archives are not the point / data should be omitted (a la in Semantic Catalogs)

4- time for fuckin bed.

==========
Sun Mar 05 00:19:37 -0800 2017

Progress on catalog / fg manager refactor:

 - make upstream the *default*- only replicate entities into downstream archives when asked
 - catalog is stupid. why base the whole thing on a fragile sequential index?

 - catalog refs should be [catalog, ref, id] where ref is LcArchive.ref, and the catalog manager looks it up into a list.
 - that way, each serialized entity is completely specified on its own.

 - catalog manager should dereference and should load on demand

 - and some sort of librarian should have a master list of all the entities.
 - gzip catalogs should omit data (just like I said)

 - don't feel like switching into code mode right now
 - load should recurse on upstreams.

But the point is, the catalog ref can be assigned a catalog manager.  CatalogRef.lookup(catalog) should dereference it and be immutable.
And then the catalog manager stores its list of known catalogs by .ref

Foreground: is upstream of all archives that don't have an upstream.  archives that do have an upstream, load them recursively, until you land back at foreground.  that's your ordering.

then from each archive, you can look up -> fg flows as interior, non-cutoff; fg emissions as cutoffs.


 - background:
   : already spits out a list of fg fragments and outputs
   -> need to move it into main
   -> get rid of extraneous stuff in LcArchive as well, with terminations and such-
   -> background should report: it all. entity map: Af entities (foreground sccs), Ad entities (background + downstream, interior), Bf entities (cutoff)
      -> background should aggregate- via inversion for Af and iteration for A*? that's the shit I havent done yet
      - should create fragments and give them UUIDs (uuid3 via termination? no. simply enumerate them.)
      - the fragment's origin then becomes whatever foreground queries it. 

   - manager should: ask for a list of fragments
     : given one fragment - get children-> column of af
       	     	 	  - fg inventory -> columns of ad and bf
			  - bg lci -> column of bx
     : foreground should then ask flow db for cfs for the named flow, given the qtys loaded.







==========
Tue Feb 21 13:35:50 -0800 2017

OK- progress- we now have built A and B matrices, and we have an Ecoinvent Tarjan traversal in <25 sec, which is shorter than it takes to load the JSON file. (AND we implemented allocated exchange deserialization)

Moving forward, on the refactoring side: we need to
 * figure out what the foreground should do, and how matrix bg computation should fit into it
 * figure out an interface for the foreground manager-- I suppose this should do that
 * split entities / move deserialize into entities + exchanges
 * flowdb -> quantity db; move to catalog from mgr

 - review catalog, develop interface
 - review interfaces


What is currently required to perform foreground queries?

 - retrieve quantities from index 0 by uuid
 - fragment_lcia(frag, **kwargs)
 - fg_lcia(catalog_ref)
 - frag(abbreviation)
 - ref(index, id)

fg_lcia simply dereferences the process and runs the process's lcia
fragment_lcia simply requires each fragment's score cache to be set-- it's practically static

so what about compute_unit_scores? static, static, static.

what does the manager even do? it's just a collection of utility functions.


The whole thing needs reworked.  None of the current manager tasks need to be done by a manager- they should be done by the entities themselves.  A process can compute its own fg_lcia (and with matrix, its own bg_lcia)

except not, because the foreground flows are supposed to be the ones that are characterized.  The foreground should be doing the lcia-- the archives should just be doing LCI? but that still doesn't help because the LCI they return will include heterodox flows.

They should return Emission objects- just a flow uuid and direction (and value) and then the foreground can do the LCIA using its "correct" flows of record (which are rendered correct through the use of a quantity db)

The Foreground should NOT store fragments, though-- the manager should store fragments.  ALL the manager should do is store and manage fragments and their unit score computations.

A SEPARATE builder class (not a subclass) should be used for consstructing fragments which can then be added to a fragment manager.

The manager should still be made up of a catalog.

All the "child flows" and "fragment to foreground" stuff was written blind- it should all be thrown out. I should start new.





Vision for how things should work:

 * Entities: get separate files.

 * LcArchive:
   * can be marked background- if true, then entities may not be added; and edits (esp. to process reference exchanges) may produce unreliable results.
   * once an archive is marked background, the archive can identify:
     -- foreground flows (product flows in non-background sccs)
     -- background flows (core and downstream)
     -- cutoff flows
     * for a given process+ref flow, return interior exchanges (exchanges found in _terminations)
     * for a given process+ref flow, return direct cutoffs (exchanges not found in _terminations)
     * for a given process+ref flow, return LCI (agg cutoffs)
     == all of these are delivered as (flow.uuid, direction, value)
     [=> dissipation flows only work in the foreground]
     * background can also return disagg or agg foreground, dependencies, emissions
     * foreground does LCIA computation on the results
     * archives can also be mined to construct fragment trees, instead of the absurd build_child_flows and the like
     
   ** problems: mainly we want the compartment manager to detect intermediate vs elementary flows, but that is something that we really want the entities to do for themselves.
   ** it's not really intermediate vs elementary that we're interested in, though- it's interior vs exterior-
      - for gen_exchanges we want interior flows to build child fragments
      - for lcia we want exterior flows to estimate impacts
      - what knows interior vs exterior? **the background!** how does it know?
      	- _terminations tell us whether flows are interior or exterior- the problem is initializing it-
	  = what happens if a process's reference changes- how does _terminations get updated?
	  = either we disallow that, or we have to provide hooks. hooks don't seem feasible.
	  = what we CAN do is disallow new entity addition after bg is computed- but that still doesn't prevent changes to existing processes. I think it's just a "void your warranty" situation: once the bg is computed, you can't mess with it anymore.
	  So anyway, the key into _terminations is the same as the key into _emissions: (flow uuid, direction) from a parent exchange.  Except _terminations is complete; _emissions only includes emissions that are part of the background.  So membership in _terminations should be the determining factor for interiority.

	  This is great- this completely eliminates the need for a compartment manager. And since we create _terminations on __init__, we don't even need to build the background!
	- emissions are a list of flows + directions- those we can find right away using the bg.



 * Quantity DB: as before, maps flowable + compartment to CF.
   -> contains its own compartment manager, serializes to compartments.json
   -> compartment manager should also compartmentalize & dereference quantities -> semantic


We still would need to load the whole archive before we can initialize background.


 * Catalog--> contains a foreground and a quantity db.
   -> serializes to catalog.json-- should include fg-specific flow synonyms as well

 * Catalog[0] is foreground:
   -> privileged archive because it stores authoritative flow profile data
   -> serializes to entities.json in catalog directory

 * FragmentManager is built on top of a catalog
   -> keeps a list of fragments; serializes + deserializes them in the fragments/ directory in foreground
   -> all the tricky fragment creation stuff comes out--> done using matrices instead.
   -> backgrounds create fragments now, and hand them over to the manager to store.
   


In order to "do everything", which in this case is compute a fragment LCIA,
 * I believe, to traverse, all we need is the fragment trees- we don't even use the term nodes
 * to compute unit scores:
   - if the fragment is background, do background LCIA
   - elif the fragment is foreground, lookup CFs from fragment.flow (currently using db.factors_for_flow
   - else, do foreground LCIA

Then traversal_to_lcia does not seem to make any further requirements. so- seriously- the fragments (and terms) do *all* of the work themselves! The only hard part is building them- but that will be a lot easier if archives can identify and spit out (foreground flows, background dependencies, and cutoffs)- just like in the mother fuckin paper.



==========
Sun Feb 19 00:46:06 -0800 2017

merging compartments branch with matrix: what do we want to save from the last commit?

* README

* ecoinvent_spreadsheet: refine cache loading (which we will hopefully never have to use again)

* compartments and test_compartments

* .gitignore

* entities/__init__ :
+from .quantities import LcQuantity, LcUnit
+from .flows import LcFlow
+from .processes import LcProcess
+from .entities import LcEntity

Sun 2017-02-19 18:32:28 -0800

ditching pandas.... let's do it this way:

 * make a list of all the ways the pandas sheets are being accessed (there aren't many)
 * implement a new minimal wrapper for xlrd that emulates them.
 
read_excel is used three times:
 - to read 'activity overview'
 - to read 'elementary exchanges'
 - to read 'intermediate exchanges'

'elementary exchanges' ==> _elementary

  _elementary[unitname].unique().tolist()
  _elementary.iterrows()

basically all I need is an iterrows

Sun 2017-02-19 19:45:51 -0800

Well, that was surprisingly easy. Disappointing note: ecoinvent_lcia generation workflow is distressingly out of date.


Sun 2017-02-19 20:39:52 -0800

ok- ecoinvent_lcia generation seems fine, actually.

==========
Wed Dec 21 19:13:07 PST 2016

Need to do some serious work on this shit.  Code is flung all over the place, all crazy. I need to dig through this with a pickaxe.

#1 - Compartment Manager-- that was some great (if not test-driven, then) test-supported redesign of the compartment handler.  The question is, where does that live?

The ForegroundManager has a ton of inspection processes, like compare_allocation, inventory, elementary, and so on.

The ForegroundManager also is the locus of saving and loading state files, even though those files all get saved and loaded elsewhere (?)

There's the catalog, which is a collection of archives; the archives themselves; the flow database;;; the background lookup; the foreground lookup;; the fragmentt builder


there are too many pieces. all this stuff needs to be reworked.



Wed 2016-12-21 19:26:32 -0800

Really, right now the ForegroundManager is really a WorkspaceManager-- its sole definition is a working directory.  Then inside that directory are the following files:

 - entities.json -- flows, quantities, and processes that belong to the foreground
 - catalog.json -- a list of data references
 - compartments.json -- a curated hierarchical list of compartments
 - fragments/ -- a directory containing fragment definitions
 

entities.json and fragments/ should be all that is required to host an antelope server.  In every respect, these are the deliverable products of the fragment building exercises.


# Archives

An archive is a self-consistent, monolithically managed collection of LCI data, that is, of entities.  Archives have a low-level interface

# Catalog

The catalog is the core fixture of the tool. A catalog is a listing of data sources, each of which provides information on the entities listed above.

A catalog is a list of data sources available to a project. It also includes some other project-specific information:
 * a customizable category manager, which includes flow compartments and process classifications
 * project-specific flow identity information, to aid in characterizing elementary flows (basically, identifying existing flows as synonyms for flowables known to the flow database; see below)




## CatalogRefs

CatalogRefs are some nifty emergent tools that come out of the catalog system.  A catalog ref refers to a unique entity defined by a specified data source.  The catalog allows a catalog ref to be dereferenced to produce the entity.

are strictly created by a catalog.  Their only constitutive properties are the catalog that created them, and an index + ID that can be dereferenced by the catalog (the index is a numeric index into the catalog's list of sources, the ID is the entiti


# LCIA

The approach here is that flows know their own characterizations. It is the job of a Flow Database (really a quantity database) to allow flows to characterize themselves.  This should not happen on the fly-- but rather, the flows in a given archive should all get characterized en bloc with respect to a particular 


# Life Cycle Inventory Model Design



## Fragments


## Scenarios

Scenarios are a list of changes to a collection of entities in order to demonstrate or a particular set of circumstances or assumptions.  In the original Antelope framework, a scenario consisted of five different types of parameter settings:

 * FragmentFlow parameters (changes to fragment exchange values)
 * FlowProperty parameters (changes to non-LCIA flow characterizations, such as energy density or composition)
 * Dissipation parameters (changes to how compositions are released into the environment)
 * Emission paraameters (changes to non-composition derived emissions)
 * LCIA parameters (changes to characterization factors)

In addition, there was the intention to implement substitution parameters, where a fragment termination could be changed under different scenarios.  This was complicated because of the way the fragment structure was stored and was never completed.

In the new framework, the objective is to support all the same types of parameters, although the mechanism for doing this is not so clear.

Fragments store fragment flow parameters inherently, and compute balances during traversal.  LCIA parameters and Flow Property parameters (and the deprecated composition parameters) are really just parameterized characterizations.  Dissipations are a special type of exchanges, so both dissipation params and emission params are really just parameterized exchanges.  So the challenge is merely how to store these in the characterizations and exchanges themselves, which really comes down to serializing and deserializing them.

Which can be fairly easily unit tested.

When it comes right down to it, unit testing is the secret to the whole refactoring project we are undertaking right now but it's HARD, and part of the reason why it's HARD is because the code has no testing whatsoever at the present time, and so there is no way to tell (other than myself sitting and thinking hard about it) whether any given change is going to work.

At the end of all this, the code will be substantially improved.  The question is-- the problem is-- how long will it take to get to the end of all of this? I'm already behind on the Patagonia Virent annex, and I'm arguably behind on the AUOMA project, which from an lca-tools perspective I *haven't even started yet*.





==========
Tue Jan 10 14:18:02 PST 2017


Exchange refactoring.

Allocated exchanges are a terrible abuse of code.  Desperately need a test suite (read: a functional definition) for exchanges.  Right now the thing causing the issue is some stupid shit with validating allocated exchanges, where I assert the reference value for the reference flow must be nonzero, and the non-reference value for reference flows must be zero.  That's causing problems for processes that list their own reference outputs as inputs, which is not a problem *as long as the nonreference factors get added together* when the matrix is constructed.  I'm sure this is what ecoinvent does.  well, who can be sure?

anyways-- it's coming up at all because I monkeyed in these runtime assertions to validate the allocated exchanges since I never bothered to define their functionality with tests.

Can we confirm this is the case in some other application?

Yes- in the APOS case, the heat and power co-generation process has the same exchange listed [the one causing the error] (twice; once 0) as an output and twice as an input.

so I am going to simply ignore the errors for now, and fix on the refactor.



Tue 2017-01-10 14:39:38 -0800
seems to be working. FYI, refactoring exchanges into a dict from a set has also eliminated the slow performance, even from zip (somewhat: 5000 processes in 53 sec; and counting)
125.66 sec to load 12966 processes.

ok, heading to campus


==========
Wed Jan 11 22:42:17 PST 2017


Proposal: mush all outputGroup 0 + 2 flows into reference exchangess on initial Lc load.  that would mean diluting the meaning of reference exchanges (but they're already allowed to be multiple)


need tests! need a spec!

Here's what a process inventory should be able to do:

I = ProcessInventory(catalog_ref)

I.




Here's what I would like to accomplish:

LC = LcArchive(catalog)  # e.g. from json

p = LC[process-key]

p.exchanges() should yield exchanges

p.exchanges(flow-ref) should operate as (and replace) p.allocated_exchanges()

p.exchange(flow-ref, direction[=None])  # all instances
  basically FirstOrDefault()
  if query returns multiple results, raise exception; StopIteration returns None.

p.exchange(flow-ref, ['Input'|'Output'])

p.reference_entity is a set of exchanges

p.references() should yield references


x = next(p.references())

x[ref-flow] returns exchange value under allocation for ref-flow

we should strive to make allocation specified as simply as possible at the process level
but exchanges, if they store it, should also know (?)

exchanges have got to be thought of as observations

So x = an ExchangeValue() which can be specified statically at invocation [as a dict]

x.value is the somehow-designated (first observed) exchange value- should be immutable.  But all exchanges should be AllocatedExchanges, in the sense that all exchanges should have dicts of values. of observations.  which could be e.g. node terminations.

the million dollar question is whether I need to preserve the outputGroup designation-- and I think no.  The question has got to be, how am *I* using it?

Currently, ecospold.py raises an exception if it sees multiple references.  ecospold2- wow, ecospold2 just calls them all outputs and grabs the reference from the filename.  If you want a separate reference you have to load a separate file, I guess.  but unlinked processes? it doesn't know. since it ignores that part.

what about the serialization? no harm, no foul- ecospold v1 processes will never have multiply-valued exchanges; ecospold v2 processes (unlinked) currently are also all single-valued, and (linked) the change should have no effect on the reference flows.

I currently don't use it in the foreground-- (where do I query ecoinvent processes? for LCIA, where the reference should maybe be made mandatory)  but then in cases where I do expect a singular, I can catch that according to the spec.  In building fragments I just grab all the intermediate flows.  which is to say, I ask the compartment manager. that would include all reference flows.

so it's resolved-  ecospold loaders should mark outputgroup 0 and 2 as reference flows.  That solves half the problem of pre-loading uslci.

ecospold2 loaders should look at the byproduct classification

p.reference()
  yield the first or None; raise if multiple

so what do I do if I catch that?  when would we do it? only if not specified. on query it's known - term_flow is known - so it's not a problem.

And the exchange should simply return the value for the term_flow.

okay, so we have our refactor.  Then loading exchanges should simply be registering observations.  much simpler.

that's all there is to it.  If a flow has extra references defined- fine.

anyways.... how do we use this to build
