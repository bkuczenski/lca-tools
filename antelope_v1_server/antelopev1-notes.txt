==========
Fri Sep 14 13:48:35 -0700 2018

I am losing and re-learning all this flask stuff.

Here's the deal.  The flask server does not *appear* to *normally* be runtime-configurable.  Meaning, it does not appear to be straightforward to e.g. first startup a flask server and then add foregrounds to it.

anyway, even if it's not supported to do that in real time, I can still write the AV1 routes as a blueprint.  that's what I should do.

The workflow would be:

 0- have an LcCatalog that contains the fragment you want to publish
 1- create the study object
 2- from the fragment, add to the study object by (a) crawls the fragment and (b) accumulates lists of processes, flows, flowproperties
 3- add lciamethods at any time
 4- supply the study object to a blueprint factory that produces the blueprint
  4a- add the blueprint to the flask app


    


==========
Mon Mar 19 22:15:39 -0700 2018

Flask app should be route-based and not subclassed

App instance includes a single LcCatalog (open question: which owns the other?)

flask blueprint to initialize AntelopePublisher, which spins out StudyPublications to service API requests. easy mapping of url prefix to StudyPublication, and then server performs queries

for a request that doesn't match a registered publication prefix, fallback to LcCatalog lookup, where the first arg is the semantic reference and the second arg becomes an AV2-equivalent lookup into the catalog.

the pub ITSELF should just be a list/mapping of links/sequential IDs to catalog entries.

Fri 2018-03-23 14:40:36 -0700
SCENARIOS are a bit fuzzy.  I suppose in the BAREBONES case there don't need to be any scenarios (though scenarios + params were kind of the whole point of antelope when it first came together)
(that's not true- the point was the provenance framework)

Anyway, there are two kinds of scenarios:
 1- scenarios designed by the study author; can be selectively exposed to or concealed from viewers
 2- scenarios created by viewers to test hypotheses; should be kept private 

IT IS TRUE that in the original case, the server stored the users' params.

HOWEVER, I think the better approach is to follow git: for the user to basically fork the model into their own local container and parameterize it there.  This is going to need a new client; but that's fine. The CalRecycle client can be supported without nec. supporting its parameterization abilities.

For now: scenarios are read-only, and the studypub includes a mapping of scenario IDs to parameters (and param specifications;;; vs dissipation / upr / LCIA / fp params which are hard to support-- but process params should simply be upgraded to fragments and parameterized there.  ...)

ah but flow property parameters-- maybe I still need a local QDB wtf omg we already do that
** this is obv the part to carve out from underneath and put into a graphdb **

in the fucking flow qdb. make it scenario aware when we refactor the contexts and np.

for now simply unsupported

ok so then the study publication handles the entity retrieval
the blueprint maps the queries to functions and formats the responses in json

-> or perhaps another library should do that, e.g. flask-journey
to write to the antelope spec
and handle links
yes very much


==========
Mon Mar 19 15:45:34 -0700 2018

Here's a list of all the Antelope endpoints used by the CalRecycle Frontend:

resourceService.ROUTES = {
    /** composition-related routes--> TO BE POSTPONED **/
    "compositionFlow" : API_ROOT + "compositionflows",
    "processDissipation" : API_ROOT + "processes/:processID/dissipation",

    /** core entity routes **/
    "flow" : API_ROOT + "flows/:flowID",
    "fragment" : API_ROOT + "fragments/:fragmentID",
    "impactCategory" : API_ROOT + "impactcategories",
    "lciaMethod" : API_ROOT + "lciamethods",
    "process" : API_ROOT + "processes",  /** WANT TO DEPRECATE THIS-- for now just return list of process ID and name **/

    /** entity-specific properties **/
    "fragmentStage" : API_ROOT + "fragments/:fragmentID/fragmentstages",
    "flowPropertyMagnitude" : API_ROOT + "flows/:flowID/flowpropertymagnitudes",
    "lciaFactor" : API_ROOT + "lciamethods/:lciaMethodID/lciafactors",
    "processComment" : API_ROOT + "processes/:processID/comment",
    "processFlow" : API_ROOT + "processes/:processID/processflows",

    /** compound entity routes -- basically just filters **/
    "flowForFragment" : API_ROOT + "fragments/:fragmentID/flows",
    "flowForLciaMethod" : API_ROOT + "lciamethods/:lciaMethodID/flows",
    "flowPropertyForFragment" : API_ROOT + "fragments/:fragmentID/flowproperties",
    "flowPropertyForProcess" : API_ROOT + "processes/:processID/flowproperties",
    "lciaMethodForImpactCategory" : API_ROOT + "impactcategories/:impactCategoryID/lciamethods",
    "processForFlowType" : API_ROOT + "flowtypes/:flowTypeID/processes",

    /** scenario-aware routes **/
    "fragmentFlow" : API_ROOT + "scenarios/:scenarioID/fragments/:fragmentID/fragmentflows",
    "lciaResultForFragment" : API_ROOT + "scenarios/:scenarioID/fragments/:fragmentID/lciamethods/:lciaMethodID/lciaresults",
    "lciaResultForProcess" : API_ROOT + "scenarios/:scenarioID/processes/:processID/lciamethods/:lciaMethodID/lciaresults",
    "lciaTotalForFragment" : API_ROOT + "scenarios/:scenarioID/fragments/:fragmentID/lciaresults",
    "lciaTotalForProcess" : API_ROOT + "scenarios/:scenarioID/processes/:processID/lciaresults",
    "param" : API_ROOT + "scenarios/:scenarioID/params/:paramID",
    "scenario" : API_ROOT + "scenarios/:scenarioID",
    "scenarioGroup" : API_ROOT + "scenariogroups/:scenarioGroupID"
};


Dissipation endpoints are ignored for now-- those are very low priority.

Also let's neglect scenarios for the moment-- though that is a large question mark and the API is going to need to handle POST and PUT data for scenarios-- perhaps a sql-like backend is appropriate for that-- in which case perhaps a sql-like backend is appropriate for at least mapping the entities from index to semantic link.  but for now the db is going to be just a defaultdict(list) (ZOMG!)
