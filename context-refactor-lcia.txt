==========
Thu Apr 11 09:21:59 -0700 2019

OK we are so close, rolling on up to Promontory Point, but we are still a bit off.

After quite some rumination I think I have the following model in mind:

 - When using the catalog, we only want to deal with quantities that are local to the qdb.  This means we want to give back either:
   * quantities whose _qi is a local.qdb implementation
   * quantity refs whose _query is to local.qdb
   that will ensure that the LCIA Engine gets all the requests for information.

 - At the same time, the quantity refs from non-qdb sources (including non-local sources) are self contained because bejezzuz if I didn't pull that off then what has all this effort been for anyway?
   * the locally-stored refs have the capacity *themselves* to retrieve their own factors; do quantity relation; etc, but the user will never see them unless they access the resource directly
   * instead, the catalog query will masquerade them
   * we want to store those quantity refs IN the local qdb archive, so that basic operations work to find them.

 - THE WAY IT ALL WORKS
   * anytime we get a non-canonical quantity, we want to make a canonical version
     - CatalogQuery intercepts get_canonical to ask _tm first
       + first we try to tm.get canonical
       	 = if it's found (and for paranoia we can check to see if its query is local), we're good- send it off
	 = if it's not found, we need to add it
	   --> add authentic ref to qdb entity store
	       + if its external_ref is already known, then we are kinda screwed
	       + no, we'll use links as entity keys, as in foreground. this is getting complicated and buggy.
	   --> create a new "masquerade" CatalogRef.from_query(local.qdb) and install IT as the canonical quantity; make sure that the link and external ref lookup to the masqueraded 

     - CatalogQuery intercepts make_ref AFTER THE FACT and runs get_canonical on the ref
       	 = so again: the authentic quantity_ref is stored in the entity_store
	 = the masqueraded quantity_ref is the canonical quantity
	 = the masqueraded quantity_ref has a query that is linked to the lcia engine, not the authentic source
	 = get_canonical(authentic quantity_ref) => masqueraded quantity_ref
	   --> this implies a mod to LciaDb.add() because that is the point where the qty is added to the tm
       + add/merge it to lcia engine (and import cfs)
   * we want to ask local.qdb first, not last, in gen_interfaces


Thu 2019-04-11 11:16:56 -0700

Shit. Another 90 minutes spent and we are... maybe incremntally closer? Now we are in context hell so I need another 6 hours to think + fix...
off to other things.



==========
Tue Apr 09 10:05:06 -0700 2019

Forward with testing.. getting a missing exchange error in configure.set_reference() why? because non-reference flows have their context as termination.  What should we do?
I think the most expedient thing to do is also the best: simply squash the termination.  This means we need to remove and replace the exchange, since termination is part of its hash.

Wed 2019-04-10 10:17:52 -0700

LCIA is not working for complex reasons, and there are at least two major points of incoherence in the code:

 (1) get_canonical is not used/behaving as expected
 (2) context lookup is not well defined w/r/t the NullContext singleton. Alternative ideas are:
     x NullContext applies to every failed lookup (deprecated)
     - NullContext matches every context
     x NullContext matches no context (facially wrong: unit conversions are intended to be stored with NullContext)
     x NullContext signifies an error

Related observation: it is an error for any interface method to return None.  It should return something or raise an exception.  I'm looking at you, get_context()

OK, so here's the deal.  EntityStore.__getitem__ returns None if no entity is found (i.e. catches KeyError), but SynonymDict.__getitem__ raises KeyError
CompartmentManager returns NullEntry for nonspecific items
ContextManager also returns NullEntry for disregarded items
they all still raise KeyError if nothing is found.  This is still consistent with SynonymDict (since in the two exception cases the object *was* found) but inconsistent with archive
And that's fine.  In fact the structure of AbstractQuery is premised on that- which is why None leads to the fallback exception (should maybe be EntityNotFound for those cases)

The question is for the TermManager- whether we should raise a KeyError or return None.  The code seems to assume we return None- which makes sense because the context is meant to be "entity-like".
So let's preserve it, and use NullContext strictly for affirmative identifications of cases where no context (or all contexts) applies, and tentatively assume NullContext matches any context that has not encountered another match (assuming dist>=3)
Then get_context returns NullContext if tm[cx] is None, and client code can handle that.  Exchanges already drop NullContext on __init__ (resulting in a true cutoff)

NOW... on to get_canonical
THIS method should do the following:
 - given a quantity or reference to a quantity,
   = return the corresponding canonical quantity already known
   = if no corresponding canonical quantity is found, raise a KeyError
   - the CatalogQuery is a special case: if the quantity is not known,
     = create a new canonical quantity from the information given
     = must provide a way to merge quantities
       * the challenge here is to make the merge persistent- i.e. to automatically store merged entries as synonyms that will get reintroduced
       	 The preferred solution to that is to use the entity_store- i.e. to add synonyms to the canonical quantity entities that get serialized
	 But we have not tackled serialization at all yet, which carries challenges with qty refs--
	 except we don't need to. We can: on merge, update the canonical qty's synonyms property. but we haven't added any non-local qtys to the qdb entity store. Then when the qdb gets saved, only local qtys will get written, including synonyms from the merge.

OK, so that needs to be done:
 x write code to store synonyms on merge of QuantitySynonyms objects
 x write tests for that
 .. write tests for qdb serialization
 x write a client-facing method to merge catalog quantities
 0 is that an interface method?
 Let's take a break and percolate on this, then implement it later.

==========
Thu Apr 04 10:52:40 -0700 2019

We are almost done! But I want to fix the interface.

 - add_characterization requires an explicit origin or else it defaults to the origin of the query quantity
   proposed solution: use the characterize() method of the interface
   The problem is that most of these use cases don't already have interface instances.  So I think we just audit them and switch where appropriate.
   add_characterization() 14 uses
    - quantity implementation characterize() - here we actually want to use it
    - configure implementation - should probably use it here too
    x antelope v1 quantity impl
    - term_manager - keep
    - archive _add_chars() - go ahead and use it
    - providers: traci, ilcd_lcia, ilcd, olca, ecospold - they quantity is already local
    - ecoinvent_lcia - added origin

   For testing, though, we should go ahead and use the quantity interface

 - QRResult = QuantityRelation Result. quantity_relation() should return a QuantityRelation Result!

 - cf - characterization factor. cf() should return a factor (pure number)! so these are switched

 - audit positional argument sequences:
  Flow-specific:
    def profile(self, flow, **kwargs):

  Quantity-specific
    def get_canonical(self, quantity, **kwargs):
    def factors(self, quantity, flowable=None, context=None, **kwargs):
    def do_lcia(self, quantity, inventory, locale='GLO', **kwargs):

  Characterization:
    def      characterize(self, flowable, ref_quantity, query_quantity, value, context=None, location='GLO', **kwargs):
    def                cf(self, flow, quantity, ref_quantity=None, context=None, locale='GLO', strategy=None, **kwargs):
    def quantity_relation(self, flowable, ref_quantity, query_quantity, context, locale='GLO', **kwargs):

    looks like it's in order. The only defect is with cf() because it expects a flow instead of a flowable, so ref_quantity is a kwarg and not an arg.

done. Thu 2019-04-04 11:51:36 -0700



==========
Wed Mar 13 17:07:12 -0700 2019

We are doing terribly. But we are close!

Auditing quantity implementation=-- what term_manager methods do we use?

 * get_canonical()
 * factors_for_quantity() [implements factors()]
 * add_characterization() [implements characterize()]
 * factors_for_flowable() [implements quantity_conversions]
 * __getitem__ [retrieves canonical context]

seems good.
Let's do ExchangeValue.__new__

The situation here is:

 * Exchange has 4 parts: parent, flow[able], direction (wrt parent), optional termination
 * termination = None means exchange is a CUTOFF
   = REFERENCE exchanges are the allocatable subset of CUTOFF exchanges
 * termination = Context with Context.elementary = True means exchange is ELEMENTARY
 * termination = Context with Context.elementary = False means exchange is a CUTOFF
 * termination = str means exchange is INTERMEDIATE
   = implication is that the termination must lookup as a valid external_ref in the local archive
     - if you want to terminate to something outside the local archive, use a fragment

Exchanges are created ALL OVER the code.  (17 usages in import statements)

So:
 (a) we need to change the invocation in many places and
 (b) we need to validate the instantiation.

Let's list all the usages:

antelope_background.background.implementation:
 (118) foreground() - yields ExchangeValues constructed from ExchDef() which come from TermRef()
       (should yield strictly intermediate exchanges, except for reference)
*(122) _direct_exchanges() - yields EVs
       	+ from _generate_exchange_defs() in the case of dependencies() or ad()
	+ from _generate_em_defs() in the case of emissions() or bf() or lci()
	= PROBLEM! the FlatBackground class has no archive and cannot access Contexts
	  - this means we need to do it in the bg implementation
	  - easy enoughh- just add a kwarg to _direct_exchhanges() that specifies whether to retrieve a context from tm prior to creating the ExchangeValue

antelope_background.engine.background_manager: (OldBackgroundManager)
 12 uses; obsolete so don't bother with this-- should be deleted from ContextRefactor

antelope_catalog.providers.ecospold2.ecospold2:
 (522) retrieve_lcia_scores(): used to create reference exchange; no changes needed

antelope_catalog.providers.v1_client.inventory:
*(72) _add_lcia_detail(): used to provide the exchange argument to LciaResult.add_score()
      - context should be supplied for completeness, but not required for functionality at this time

antelope_reports.tables.allocation:
 (87) _add_alloc_refs(): used to create a reference exchange for table output; no changes needed

lcatools.lcia_results:
*(412) LciaResult.from_cfs():
       - context should be supplied for completeness (grab from CF), not reqd. at this time
0(568) flatten():
       - context should be supplied for completeness (cannot grab), not reqd. at this time
0(586) flatten():
       - context should be supplied for completeness (cannot grab), not reqd. at this time
     
lcatools.terminations:
?(211) to_exchange():  ## is this method even used? It seems broken

*(389) _unobserved_exchanges(): used to generate exchanges for characterization of fg emissions
       - definitely needs fixed.  term_node should BE context in this case.
       ** this leads us to a FlowTermination refactor-- put on stack

lcatools.entities.fragments:
0(1012) inventory():
	easy fix (pending FlowTermination refactor)- just provide term.term_node as termination
	     (actually: need term.term_node.external_ref for non-fg-emissions)
	(actually: nothing to fix, as exchanges in inventory() are all cutoffs)

 (1077) cutoffs():
 	no change needed- they're cutoffs so termination should be None

lcatools.entities.processes:
x(353) inventory():       ** need to refactor ExchangeValue.from_allocated()
x(359) inventory():       ** need to refactor ExchangeValue.from_allocated()

*(573) add_exchange(): fix upstream
*(577) add_exchange(): fix upstream
*(581) add_exchange(): fix upstream
       ** need to fix all invocations of add_exchange()

11 upstream invocations of add_exchange:
   : 3 in process from json (!!! do we want to be back-compatible?)
   : 1 in olca JSON-LD
   : 2 in ecospold2
   : 1 in ilcd
   : 1 in ecoinvent spreadsheet (only ref- drop)
   : 1 in ecospold1
   : 2 in tests

Tasks on the Stack:
 X background _direct_exchanges()
 x LciaResult refactor: audit use of QRResult
 X v1_client.inventory _add_lcia_detail()
 0 LciaResult.from_cfs()
 x FlowTermination refactor:
    - top-to-bottom review
    - __init__ type checking
    - __init__ invocation checking
    - _unobserved_exchanges()
    - use of is_fg; add is_context
    - serialization: context serializes as 'context' not as {'origin':, 'externalId':}
    - deserialization: symmetric to above; try for bg compatibility
    - __str__, other diagnostics
 0 fragments.inventory()
 ** add_exchange() upstream

That's not half bad, actually.

and then remains:
 - just the CatalogQuery to hijack get_canonical
 - and rewrite the interfaces. let's do that now
I think we could get to the testing stage in 8 h work.


Fri 2019-03-15 13:48:10 -0700

HOLD ON for a fucking second.

HOW EXACTLY is LCIA supposed to work in the new order?
In the old order, we always used do_lcia() as a QuantityRef method, which fell back to the query implementation of do_lcia, which always felt like a hack.

In the new order, do_lcia is properly implemented in the Quantity Implementation- which returns it to the normal _perform_query() mechanism I THINK.... no need for a BasicQuery overriding implementation. 

Fri 2019-03-15 15:05:27 -0700
OK OK this is all good.

Remaining tasks:
 ** add_exchange() upstream
 - CatalogQuery.get_canonical()
 - implement the index interface
 - BIG FAT TESTING


==========
Fri Feb 15 12:54:22 -0800 2019

Where are we at?

OBJECTIVE: COMPLETE CONTEXT REFACTOR BY 1 March 2019

What does this mean?

 - Qdb, old Synlist, old CompartmentManager are GONE
 - Exchange.termination returns a CONTEXT, a string, or None
 x Archives have a TermManager which maps strings to objects, many-to-one.  Flowables map to strings, which are the canonical names of flowables; contexts map to Context objects
 x Flows can have a context or not-- archives derived from traditional data sources will work the same; but the term manager will be able to easily spit out flowables
 - 'Compartment' loses all special meaning except in instantiation
 - Characterization Factors are serialized separately from flows, though they can still be deserialized the old-fashioned way
 - Interfaces rewritten to include flowables and contexts, along with flows, in index

Mon 2019-02-18 15:26:06 -0800

Current usage of Term Manager // Quantity Interface

 Quantity Interface provides:
  - synonyms (obsolete)
  - flowables (to index)
  - compartments (to index.contexts)

  - get_canonical(quantity):
  - profile(flow): list of cfs for a given flow
  - characterize(flowable, ref_quantity, query_quantity, value, context=None, location='GLO')
  - factors(quantity, flowable=None, compartment=None)
  - cf(flow, quantity, ...) - returns the best cf
  - quantity_relation - returns the value of the best cf
  - do_lcia(quantity, inventory, ...) - iterates over inventory

 Term Manager provides:
  - __getitem__(context)
  - add_flow(flow)
  - add_characterization(...) implements characterize()
  - get_canonical()
  - qlookup() -> returns the flowable-to-factor lookup
  - factors_for_flowable() -> used to implement everything
  - factors_for_quantity() -> wraps f_f_f, implements factors()
  - get_flowable() -> for index
  - flowables() -> for index
  - de/serialization -> for ops

They are HIGHLY overlapping. The question is: is there a normative / design decision that distinguishes the Term Manager from the Quantity Interface? from the Quantity entity

Because remember we have this draggy situation where the quantity entity has to be given an interface- but that's not so bad- that just wraps up the term manager

and YES there is a normative / design decision: the term manager contains all the functionality that gets subclassed by the LciaEngine to work across data sources! boom end of story. stop with the endless introspection and move forward already!


==========
<<<<<<< Updated upstream
Thu Jan 11 10:26:15 -0800 2018
=======
Thu Aug 30 12:17:56 -0700 2018

I think today is the day for me to start the LciaResult remodel, as that will dictate how the new exchange world order is supposed to work.

Mon 2018-09-03 15:51:51 -0700



>>>>>>> Stashed changes

Since last September, we have considerably reworked [simplified] the interfaces system, but we are NOT DONE YET.

The following two major changes need to be made, both of which strongly affect LCIA:

 (1) 'flow' as a base entity needs to be abandoned in favor of 'flowable'-- reduce by 10x the number of entities in the db-- and 'context' needs to be added as a new entity.  Flow['Compartment'] is no longer A Thing; instead, an exchange terminates in a context:
 process-flowable-direction-context for elementary flows;
 process-flowable-direction-process for terminated intermediate flows;
 process-flowable-direction-None for cutoff flows (and reference flows)

This vastly simplifies the QuantityInterface implementation.

Moreover-- we have been talking about abandoning Qdb but I think the thing to do is retain Qdb-- and YES, give every antelope container its own private Qdb that it POPULATES by querying a public Qdb-- and have the DetailedLciaResult LOOKUP the factor in the Qdb when the exchange is specified.

Well, maybe that's a bridge too far. But it would be kind of neat if LciaResults were spun out by LciaEngines.

I wonder- let's enumerate all the places LciaResult()s are created, and see if a Qdb is accessible to (m)any of them:

<<<<<<< Updated upstream
* in LciaResult:
+  - add() 
+  - aggregate()
+  - flatten()
* in LciaResults:
  - __getitem__ [for null]
  - apply_weighting()
* in fragment_flows:
  - frag_flow_lcia() --> replaces traversal_to_lcia(); should be part of LciaEngine?
* in FlowTermination:
  - compute_unit_score [for null]
  - _deserialize_score_cache
* in LcProcess:
  - lcia()
* in EcospoldV2Archive:
  - retrieve_lcia_scores()
* in Qdb:
  - do_lcia()
* in AntelopeV1Client:
  - fragment_lcia()
  - lcia()
  
=======
 - test term manager but it's basically working
 - quantity relation is now implemented by the quantity
   = qlookup maps flowable to clookup
   = quantity clookup should be strict- errors flagged when a duplicate cf is added
 - move do_lcia into quantity interface
   + do_lcia is the only place that creates LciaResults
   + DetailedLciaResult changes to have the following components:
     - contextualized exchange or exchange ref
       	 equivalent to { node ref, flowable term, direction, context, exch val }
       = factor.value
       = location='GLO'
   + input is iterable of exchanges. algorithm is to:
     = lookup flowable in [quantity's qdict or query's qlookup]
     = further lookup context in traversing clookup
     = generate an lcia detailed result from exchange by associating a quantity relation result
     = lcia result has 4 sets:
       * cutoffs, which have null or non-elementary terminations
       * Lcia Scores, which have nonzero results
       * Lcia Zeros, which have zero or NoFactorsFound lookups
       * Fail, which reports exchanges that either had convert fails or flow / reference qty unknown
 - lcia engine is reimagined -> qdb will be ditched and replaced by current lcia engine
   = it's still a basic archive subclass, which reimplements the quantity interface
   = has its own quantity dict which maps quantity term to qlookup owned by the archive instead
   = that qlookup maps flowable to a SClookup
   = SClookup allows multiple cfs for the same flowable/quantity pair and resolves them at query time {i.e. as currently implemented}
 - all this can then be easily de/serialized for http
 - then we need to generate the reference context + flowable sets
 - then qdb is obsolete, it comes out / lcia engine renamed to qdb
 - then we need to reimplement the flowable / context / synonym in the index interface
 => and then we pop back to antelope v2
>>>>>>> Stashed changes

X in traversal_to_lcia() ==> moved to fragment_flows; unused

OK... we'll look that over a bit later and see if we can shrink that down.  But remember: in cases where the quantity arg is a catalog ref, the Qdb is available via the catalog.

Thu 2018-01-11 13:14:50 -0800

Thinking about this further.... giving the antelope container a Qdb causes problems as well: does it provide a quantity interface? I guess it does- to validate that its factors are the same as a reference.

The whole function of the Qdb is to abstract flow and container descriptors into "flowable" and "context" objects with synonyms.  If we give up the Qdb then we have to re-implement that functionality.

Instead, when we receive a quantity spec- we check to see if it's in our local set of lcia methods- and if not, we retrieve it from our reference Qdb- over the web via the antelope 2.0 interface.  So an antelope client is required to implement the antelope server? that seems dangerous.

They will be different subclasses of LciaEngine-- one for static archives and one for catalogs.  That's the part for me to work on right now.  

The only difference is in load_lcia_factors(). The Static Archive version implements load_lcia_factors(qid) by querying a stored remote Qdb resource.  The Catalog version works as currently written.

Mon 2018-09-03 16:49:44 -0700

FYI, quantity NEEDS context manager because, when we add_characterization, we then ask the quantity to register it with the cm.  So either the flow or the quantity (but logically, the quantity) needs a link back to the cm.




DEPRECATED
==========----------------------------------------
Mon Jul 30 14:19:41 -0700 2018

Context Manager methods:

 - add_context(string)
   = return string if successful

 - _create_flowable(string)
   = return string if successful

 - add flow-context linkage(flow with 'Compartment' or flowable, context, uuid)

 - add_synonym(existing_term, *new_terms)
   = raise if existing_term doesn't exist, or if any of new_terms do exist

 - getitem(term)
   = return None if not present
   = return uuid for entity if present

 - list contexts

 - list flowables

 - list contexts for flowable


Expectations:
 - BasicArchive stores contexts, flow(able)s, and quantities by uuid or otherwise valid entity key

 - context manager interceps requests for non-entities incl:
   * string names and synonyms for contexts
   * string names and synonyms for flowables
   * uuids that correspond to flowable-context pairs
   = and returns the uuids for the appropriate entities (context, flowable)

 - given a flowable, context manager should know all contexts in which it has been observed/reported
   * this is generally limited to elementary flows and only for classical archives that use the old flow definition;;;;;;;;;
   * terminated intermediate flows and exchanges defined with elementary terminations to flowables will not be known to context manager
   * however, archives that contain characterization data will be known

 - quantitative characterization information is unknown to context manager unless it is dependent on a flow-context pairing, in which case the existence of the characterization will be implicit but the value will not be known


==========----------------------------------------

Characterizations:

Now a characterization requires a flowable, a quantity, and an optional context.  It is still otherwise identical, except the natural direction is taken from the context instead of stored locally.


==========----------------------------------------

Qdb extension:
 - inherits from basic archive

 - pre-populates context manager with comprehensive list of flows and contexts
   * since this is expected to be moderately costly, it should only be done once per catalog (i.e. in the Qdb and not in the archive-generic context manager)

 - also adds a synonym list for quantities
----------
==========
----------

BELOW IS OUT OF DATE

==========
Tue Sep 19 16:42:04 -0700 2017

Complete mess right about now.

Here's the situation:

 - LcCatalog implements lcia() but this should be done by the catalog ref, in the inventory interface, for either process or fragment.
 - ForegroundCatalog implements fragment_lcia() but this should be done by the catalog_ref, in the inventory interface, with observed=True being hardcoded (cached vs observed values are only used under the hood)
 - Qdb implements do_lcia() but this should be done by the quantity catalog ref.  It uses Qdb.convert() but this should, again, be provided by the quantity catalog ref as quantity_relation()
 - CatalogRef should be subclassed. It should instantiate the subclass upon lookup- basically as soon as it knows the entity_type of the reference.
 - Qdb.get_canonical_quantity() appears to be totally useless, its usage pattern is deeply confused, and anyway it is functionally redundant to Qdb.get_quantity()

Other issues:
 - FlowTermination currently logs subfragments, but these should be part of the FragmentFlow, because they are determined at traversal time, and to store them in the entity just begs for synchronicity problems.

Given all these, there remains more or less NO core utility to ForegroundCatalog AT ALL.

OK.  So it looks like we are shifting more stuff to the implementations- that is good- but the quantity one needs some thought.

First: compare and contrast the signature for quantity_relation() with the signature for Qdb.convert()--

Before we even get into that, keep in mind that Qdb.convert() is sprawling and occupies a considerable amount of Qdb.  The whole POINT of Qdb is convert().  and it CANNOT be localized to the quantity because it requires knowledge of other quantities. it REQUIRES Qdb.

A Quantity doesn't implement the QuantityInterface-- a provider implements the interface.  A quantity merely accesses it.  I think I am getting [more] confused.
Look- ONLY the Qdb fully implements the quantity interface.  The point of the catalog ref is to anchor the query entity to the provider.

But let's go ahead with the comparison:

self is anything that implements the  QuantityInterface:
def quantity_relation(self, ref_quantity, flowable, compartment, query_quantity, locale='GLO', **kwargs): 

self is Qdb:
def convert(self, flow=None, flowable=None, compartment=None, reference=None, query=None, query_q_ind=None, locale='GLO',
                quell_biogenic_co2=None):

They are identical, except that convert is flexible between a flow and [flowable, compartment, reference] and between query and query_q_ind, and convert accommodates quell_biogenic_co2

The point is, ONLY the Qdb is supposed to be able to implement the quantity_relation.  That was the whole reason for creating the Qdb.  The quantity merely provides a convenient way to access it-- but really that should be from the flow and not the quantity.  Or rather it COULD be from the flow just as easily as from the quantity.

ok.

routing, then:
the user, through query, identifies a flow[able + compartment] with a known reference quantity and wishes to know its characterization w.r.t. a given query quantity.
IF a proper flow entity is primary, the query would look like:
origin/flow-ref/cf/q-ref/locale -- where q-ref is a shorthand known to the catalog, and 'cf' is literal.  The implicit origin is self. 

The catalog needs to lookup the query quantity-- there has to be some way to get from the q-ref to a data source:
 * if the Qdb knows the quantity, then the q-ref should bring up an entity, which the catalog can use to track down a resource providing the quantity interface for the entity's origin.  So for that to work, the quantity would need to be present in the Qdb's quantity SynList.  That's fine- the SynList is maintainable.
 * if the Qdb does not know the quantity, then it can't lookup the cf.

On the other hand, maybe the user specifies the query quantity as primary: 

qdb/origin/qty-ref/convert/ref-qty/flowable/compartment/locale

that's an awfully complicated query statement.

Tue 2017-09-19 17:14:19 -0700
whatever whatever.

For now let's just leave do_lcia() as part of the Qdb, and only refactor how it gets accessed-- namely, by the implementation of the InventoryInterface for processes and flows, and internally by the BackgroundInterface for bg_lcia (as already done).

BasicImplementation.characterize() and its counterpart in BackgroundImplementation.bg_lcia(): these exist in order to use a specified, non-native Qdb to perform LCIA of a local inventory.  It doesn't make any sense for bg_lcia() to use this-- bg_lcia will need to know the CFs locally.  The thing to do is to add them to the local Qdb, not to specify a remote source on-the-fly.

To mix and match sources requires a runtime environment anyway-- the user can add a new resource to her resolver that will allow the quantity's factors to be retrieved and loaded locally.
The downside of that is if there is a collision in the quantity SynList.  Presently, the external_ref, link, ['Name'], and __str__ are used-- so if any of those collide-- in particular the external_ref and ['Name'] preclude the knowledge of different versions of the same quantity.  It may be that the q-SynList should only track links.

I could work around that simply by setting merge=False in Qdb.add_new_quantity() on the call to add_set()-- then the name and external ref will be bound to the first entry, but the alternate cfs will still be accessible using the full link.

This means that _get_q_ind will need to find fully-specified links first.  That just means that _q_terms should be sequenced differently.
Done.

ok.

oy oy oy.

Tue 2017-09-19 17:27:57 -0700
So-- 3 minutes to wrap this up:
 - RESTful implementation of the quantity relation is still a bit sketchy
 - but local implementation should still be fine.
 - steps required:
   X get rid of get_canonical_quantity
   X move LcCatalog.lcia() into InventoryInterface-- scratch that-- no, unscratch it
   X move ForegroundCatalog.fragment_lcia() into InventoryInterface
   X move aggregate_subfragments() into FragmentFlow
   * then work on subclassing CatalogRef.

Tue 2017-09-19 17:31:17 -0700


==========
Tue Sep 19 22:23:37 -0700 2017

Let's think this through a LITTLE bit more.

We can't move lcia() into the InventoryInterface because the InventoryImplementation doesn't have access to the catalog's (private) Qdb.  BUT- both Quantity and Background already require qdbs; in both cases they just use the catalog's own.  Why not simply make the qdb publicly accessible?

Tue 2017-09-19 23:15:02 -0700

ok... checked that off... tomorrow is the testing.

==========
Wed Sep 20 15:12:04 -0700 2017

Today, that is.

Let's look into subclassing CatalogRef.
On the one hand, this doesn't seem like it would work because we want to be able to create a catalog ref without knowing what kind of entity it corresponds to.  Once we create it, we can't exactly morph it into a subclass.

One option is to have CatalogRef create subclasses through the use of class methods.  This seems trick because we can just replace invocations of CatalogRef() with CatalogRef.new().  This seems like it would be prone to circular dependencies-- we would have to have all the subclasses in the same file because the constructors would need to be able to see each other.  That is basically exchanging one antipattern (having all the tricks in one class) with a slightly less obviously broken antipattern (having all the tricks in one file).  Plus it's contrived.

Another option is to have the catalog generate the ref-- but that is undesirable because the whole genius OF the CatalogRef was its lack of dependency (currently, catalog_ref.py imports literally nothing)

So what's the problem with the status quo, exactly?  We have to police all the methods. Every method needs to check for entity_type compatibility before executing.  NEEDS TO is maybe too strong a term, but it certainly provides a courtesy to the user.

I mean, the function is not THAT long, and it grows slowly.

Let's audit:

lines 0-20: Exception classes
lines 21-26: Class definition + basic doc
lines 27-42: from_json(), accepting 'entity_type', 'origin' OR 'source', and 'externalId'
lines 43-90: __init__(), including 20 lines of doc
lines 91-95: _check_query() -- ERR_CHECK
lines 96-122: query access methods
lines 123-166: properties (including the somewhat concerning default_rx)


OK there are two different things going on, and these are the things that should be split into separate classes- and not even subclasses- totally separate classes.

First is the catalog lookup.  I specify an origin and an ID, and the catalog lookup gives me a floating reference that I can use for... well, nothing really.  All it can do is perform the lookup and give me a grounded reference that IS one entity type.

Looking over the code, there are some functions that are only useful if _query is None, and many functions that are only useful if _query is non-None.  And a few things that are ambiguous: like _d access.

I think I will create a new package called catalog_ref and give it:

A base class with origin, external_ref, and _d;
a set of entity refs that inherit the base class and provide entity-specific functionality, but require the query to be passed as an argument;
a catalog ref that inherits the base class, imports the entity classes, and provides lookup functionality and RETURNS one of the entity refs.
